{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the ATLAS Open Data Hackathon This is a documentation to run the resources to-be-released at the ATLAS Open Data project! Data and MonteCarlo samples at 13 TeV centre-of-mass energy 8 TeV Run 1 samples http://opendata.atlas.cern/extendedanalysis/datasets.php You can get/read one by one, using the URL, from a Jupyter notebook, for example. Or download the ZIP file with all in there. References Online book ATL-OREACH-PUB-2016-001 13 TeV Run 2 samples /eos/project/a/atlas-outreach/projects/open-data/OpenDataTuples/ Please, avoid any modification, you can simply read directly using LXPLUS (use it as read-only area). You need to subscribe to the e-group \u201catlas-outreach-data-and-tools\" to get access. Click here to subscribe Reference ATL-COM-OREACH-2019-002 Notes * We develop the 13 TeV TTree to be compatible with the 8 TeV TTree . * This means that in case something is developed using the 8 TeV samples, can be easily modified to fit the 13 TeV TTree . What are they? They are several collections of samples. The collections are defined by the filters that were applied. Those filters are: 1lep MC (55G) Data (54G) 2lep MC (32G) Data (2.5G) GamGam MC (635M) Data (1.4G) 1lep1tau MC (886M) Data (204M) 1tau Data (191M) MC (107M) 2tau MC (36M) Data (55M) 1fatjet1lep Data (11M) MC (6.0G) More details about the samples, production status can be seen here . Analysis Examples frameworks Explore several of the collections using the Analysis frameworks: Notes DOI and CERN Open Data access Datasets have/will have DOI's that allow their citation.","title":"Home"},{"location":"#welcome-to-the-atlas-open-data-hackathon","text":"This is a documentation to run the resources to-be-released at the ATLAS Open Data project!","title":"Welcome to the ATLAS Open Data Hackathon"},{"location":"#data-and-montecarlo-samples-at-13-tev-centre-of-mass-energy","text":"8 TeV Run 1 samples http://opendata.atlas.cern/extendedanalysis/datasets.php You can get/read one by one, using the URL, from a Jupyter notebook, for example. Or download the ZIP file with all in there. References Online book ATL-OREACH-PUB-2016-001 13 TeV Run 2 samples /eos/project/a/atlas-outreach/projects/open-data/OpenDataTuples/ Please, avoid any modification, you can simply read directly using LXPLUS (use it as read-only area). You need to subscribe to the e-group \u201catlas-outreach-data-and-tools\" to get access. Click here to subscribe Reference ATL-COM-OREACH-2019-002 Notes * We develop the 13 TeV TTree to be compatible with the 8 TeV TTree . * This means that in case something is developed using the 8 TeV samples, can be easily modified to fit the 13 TeV TTree .","title":"Data and MonteCarlo samples at 13 TeV centre-of-mass energy"},{"location":"#what-are-they","text":"They are several collections of samples. The collections are defined by the filters that were applied. Those filters are: 1lep MC (55G) Data (54G) 2lep MC (32G) Data (2.5G) GamGam MC (635M) Data (1.4G) 1lep1tau MC (886M) Data (204M) 1tau Data (191M) MC (107M) 2tau MC (36M) Data (55M) 1fatjet1lep Data (11M) MC (6.0G) More details about the samples, production status can be seen here .","title":"What are they?"},{"location":"#analysis-examples-frameworks","text":"Explore several of the collections using the Analysis frameworks:","title":"Analysis Examples frameworks"},{"location":"#notes","text":"","title":"Notes"},{"location":"#doi-and-cern-open-data-access","text":"Datasets have/will have DOI's that allow their citation.","title":"DOI and CERN Open Data access"},{"location":"datasets/","text":"Analysis codes This is an analysis code that may be used to analyse the data of the ATLAS published dataset. git and gitlab Ideally, you are able to clone a git repository, and you have an GitLab account (if you want to contribute :) C++ Python Virtual Machines (VMs)","title":"Datasets"},{"location":"datasets/#analysis-codes","text":"This is an analysis code that may be used to analyse the data of the ATLAS published dataset.","title":"Analysis codes"},{"location":"datasets/#git-and-gitlab","text":"Ideally, you are able to clone a git repository, and you have an GitLab account (if you want to contribute :)","title":"git and gitlab"},{"location":"datasets/#c","text":"","title":"C++"},{"location":"datasets/#python","text":"","title":"Python"},{"location":"datasets/#virtual-machines-vms","text":"","title":"Virtual Machines (VMs)"},{"location":"document/","text":"Building your project documentation MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown , and configured with a single YAML configuration file. Mkdocs installation Prerequisite: Python and Pip In order to manually install MkDocs you'll need Python installed on your system, as well as the Python package manager, pip. You can check if you have these already installed from the command line: On Windows: C:\\Users\\User>python --version Python 3.5.4 C:\\Users\\User>pip --version pip 9.0.1 On MacOS or Linux $ python --version Python 2.7.2 $ pip --version pip 1.5.2 Installing Python Install Python by downloading an installer appropriate for your system from python.org and running it. Note: If you are installing Python on Windows, be sure to check the box to have Python added to your PATH if the installer offers such an option (it's normally off by default). Installing Pip If you're using a recent version of Python, the Python package manager, pip, is most likely installed by default. However, you may need to upgrade pip to the lasted version: pip install --upgrade pip If you need to install pip for the first time, download get-pip.py. Then run the following command to install it: python get-pip.py Installing MkDocs Install the mkdocs package using pip: pip install mkdocs You should now have the mkdocs command installed on your system. Run mkdocs--version to check whether successfully installed. On Windows: C:\\Users\\User>mkdocs --version mkdocs, version 1.0.4 On MacOS or Linux $ mkdocs --version mkdocs, version 0.15.3 Getting started to edit Clone this documentation to your device by git Clone with ssh: git clone ssh://git@gitlab.cern.ch:7999/atlas-outreach-data-tools/hackathon-docs.git Clone with https: git clone https://gitlab.cern.ch/atlas-outreach-data-tools/hackathon-docs.git In your hackathon-docs folder, you will see a configuration file named mkdocs.yml , and a folder named docs that will contain your documentation source files. Right now the docs folder just contains all the documentation pages, such as index.md , datasets.md and the folders where the pages are saved. MkDocs comes with a built-in dev-server that lets you preview your documentation as you work on it. Make sure you're in the same directory as the mkdocs.yml configuration file, and then start the server by running the mkdocs serve command: C:\\Users\\User\\hackathon\\hackathon-docs>mkdocs serve INFO - Building documentation... INFO - Cleaning site directory [I 190705 15:13:53 server:296] Serving on http://127.0.0.1:8000 [I 190705 15:13:53 handlers:62] Start watching changes [I 190705 15:13:53 handlers:64] Start detecting changes Open up http://127.0.0.1:8000/ in your browser, and you'll see the pages you cloned being displayed: Use the editor you like to edit the files in docs and your changes will be displayed when saving them. Using the Git to commit your changes By far, the most widely used modern version control system in the world today is Git. In Git, every developer's working copy of the code is also a repository that can contain the full history of all changes. Prerequisites: Download and install Git Apply for a Gitlab account The working flow of Git: Initialize your repository with git init[directory] Clone a repository onto your local machine with git clone [URL] Edit the docs using Mkdocs Stage all changes for the next conmmit with git add [directory] Commit the staged snapshot with git commit -m [\"commit message\"] If others have modified it, you can check the updates with git fetch and update the resource with git pull . Show unstaged changes between your index and working directory with git diff Review your changes before submitting with git status Push your changes to the remote Gitlab repository with git push Reference to git cheet sheet for details","title":"Documentation"},{"location":"document/#building-your-project-documentation","text":"MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown , and configured with a single YAML configuration file.","title":"Building your project documentation"},{"location":"document/#mkdocs-installation","text":"Prerequisite: Python and Pip In order to manually install MkDocs you'll need Python installed on your system, as well as the Python package manager, pip. You can check if you have these already installed from the command line: On Windows: C:\\Users\\User>python --version Python 3.5.4 C:\\Users\\User>pip --version pip 9.0.1 On MacOS or Linux $ python --version Python 2.7.2 $ pip --version pip 1.5.2 Installing Python Install Python by downloading an installer appropriate for your system from python.org and running it. Note: If you are installing Python on Windows, be sure to check the box to have Python added to your PATH if the installer offers such an option (it's normally off by default). Installing Pip If you're using a recent version of Python, the Python package manager, pip, is most likely installed by default. However, you may need to upgrade pip to the lasted version: pip install --upgrade pip If you need to install pip for the first time, download get-pip.py. Then run the following command to install it: python get-pip.py Installing MkDocs Install the mkdocs package using pip: pip install mkdocs You should now have the mkdocs command installed on your system. Run mkdocs--version to check whether successfully installed. On Windows: C:\\Users\\User>mkdocs --version mkdocs, version 1.0.4 On MacOS or Linux $ mkdocs --version mkdocs, version 0.15.3","title":"Mkdocs installation"},{"location":"document/#getting-started-to-edit","text":"Clone this documentation to your device by git Clone with ssh: git clone ssh://git@gitlab.cern.ch:7999/atlas-outreach-data-tools/hackathon-docs.git Clone with https: git clone https://gitlab.cern.ch/atlas-outreach-data-tools/hackathon-docs.git In your hackathon-docs folder, you will see a configuration file named mkdocs.yml , and a folder named docs that will contain your documentation source files. Right now the docs folder just contains all the documentation pages, such as index.md , datasets.md and the folders where the pages are saved. MkDocs comes with a built-in dev-server that lets you preview your documentation as you work on it. Make sure you're in the same directory as the mkdocs.yml configuration file, and then start the server by running the mkdocs serve command: C:\\Users\\User\\hackathon\\hackathon-docs>mkdocs serve INFO - Building documentation... INFO - Cleaning site directory [I 190705 15:13:53 server:296] Serving on http://127.0.0.1:8000 [I 190705 15:13:53 handlers:62] Start watching changes [I 190705 15:13:53 handlers:64] Start detecting changes Open up http://127.0.0.1:8000/ in your browser, and you'll see the pages you cloned being displayed: Use the editor you like to edit the files in docs and your changes will be displayed when saving them.","title":"Getting started to edit"},{"location":"document/#using-the-git-to-commit-your-changes","text":"By far, the most widely used modern version control system in the world today is Git. In Git, every developer's working copy of the code is also a repository that can contain the full history of all changes. Prerequisites: Download and install Git Apply for a Gitlab account The working flow of Git: Initialize your repository with git init[directory] Clone a repository onto your local machine with git clone [URL] Edit the docs using Mkdocs Stage all changes for the next conmmit with git add [directory] Commit the staged snapshot with git commit -m [\"commit message\"] If others have modified it, you can check the updates with git fetch and update the resource with git pull . Show unstaged changes between your index and working directory with git diff Review your changes before submitting with git status Push your changes to the remote Gitlab repository with git push Reference to git cheet sheet for details","title":"Using the Git to commit your changes"},{"location":"C++/cpp/","text":"ATLAS Open Data C++ framework for 13 TeV analyses GitLab repository atlas-outreach-cpp-framework-13tev git clone https://gitlab.cern.ch/lserkin/atlas-outreach-cpp-framework-13tev.git About This is the C++ analysis code that may be used to analyse the data of the ATLAS published dataset. More information in the 8 TeV ATLAS Open Data PUB notes: https://cds.cern.ch/record/2203649/files/ATL-OREACH-PUB-2016-001.pdf https://cds.cern.ch/record/2624572/files/ATL-OREACH-PUB-2018-001.pdf This code is made of two parts of codes: analysis codes and plotting codes. Setup After checking out the repository, you need to setup ROOT framework and gcc compiler. The current version was compiled using gcc v6.20 and root v6.10.04 Samples For now, the analysis code can be run using samples located in eos: /eos/project/a/atlas-outreach/projects/open-data/OpenDataTuples/ Analysis Code The analysis code is located in the Analysis folder. It will be used to write out histograms for the individual input files which will be used for plotting purposes later. There are currently 7 available analyses stored as \" NNAnalysis \", where NN = WBoson, ZBoson, TTbar, WZDiBoson, ZZDiBoson, HWW, ZPrime Each analysis code contains - the analysis header ( NNAnalysis.h ) which defines the histograms and gives access to the variables stored in the input samples - the histogram header ( NNAnalysisHistograms.h ) which defines the name of output histograms - the analysis code ( NNAnalysis.C ) which makes all the selection and stores the output histograms - the analysis main ( main_NNAnalysis.C ) controls which samples are being used - the output directory ( Output_NNAnalysis ) is where the output histograms (one per each input sample) will be stored First setup the code using: * ./welcome.sh or * source welcome.sh To run the code: * ./run.sh or * source run.sh Shared libraries will be created and the analysis will run over each input sample. Estimated time it takes to run an analysis code: 15 seconds per 1M events To clean all shared libraries: * ./clean.sh or * source clean.sh Plotting The plotting code is located in the Plotting folder. * Compile the plotting code with the command: make Run the code with: ./plot [WBosonAnalysis, ZBosonAnalysis, TTbarAnalysis, DiBosonAnalysis, HWWAnalysis, ZPrimeAnalysis] [location of OutputDir_AnalysisName] Here you have to choose * 1.) which analysis you will run * 2.) where is the output of the analysis code you produced Examples ./plot ZBosonAnalysis ../Analysis/ZBosonAnalysis/OutputDir_ZBosonAnalysis The plots are saved inside the directory \" histograms \", don't forget to rename in case you run over several analyses Which histograms are being produced? This is controlled by the input file \" HistoList_ANALYSISNAME.txt \" inside list_histos Do you want to add a new plot? just add the name of it in this file (of course it has to exist in the output from the analysis code) In case you changed the Plotting code, clean first: make clean; make Auxiliary: Files.txt contains the name, cross-section, sum of weights and efficiency for each of the MC samples. DO NOT CHANGE How to add a new variable and plot it Add in the header ( NNAnalysis.h ) the new histogram: TH1F *h_new = 0; Add in the main analysis code ( NNAnalysis.C ) the calculation of the new variable: float new_variable = jet_n; Add in NNAnalysisHistograms.h in define_histograms(): h_new = new TH1F(\"h_new\", \"Description of the new variable; X axis name ; Y axis name \", number of bins , min bin , max bin); in FillOutputList() GetOutputList()->Add(h_new); in WriteHistograms() h_new->Write(); in FillHistograms() if (s.Contains(\"h_new\")) h_new->Fill(m,w); Now finally add in NNAnalysis.C the connection between the new variable and the new histogram FillHistograms( new_variable, weight, \"h_new\"); where \"new_variable\" is the new variable you calculated in 2. now run the code again over all the samples Go to PlottingCode/list_histos in HistoList_NNAnalysis.txt add one new line: h_new run the plotting code and you will find the new histogram in histograms/h_new.png !","title":"C++ framework"},{"location":"C++/cpp/#atlas-open-data-c-framework-for-13-tev-analyses","text":"","title":"ATLAS Open Data C++ framework for 13 TeV analyses"},{"location":"C++/cpp/#gitlab-repository","text":"atlas-outreach-cpp-framework-13tev git clone https://gitlab.cern.ch/lserkin/atlas-outreach-cpp-framework-13tev.git","title":"GitLab repository"},{"location":"C++/cpp/#about","text":"This is the C++ analysis code that may be used to analyse the data of the ATLAS published dataset. More information in the 8 TeV ATLAS Open Data PUB notes: https://cds.cern.ch/record/2203649/files/ATL-OREACH-PUB-2016-001.pdf https://cds.cern.ch/record/2624572/files/ATL-OREACH-PUB-2018-001.pdf This code is made of two parts of codes: analysis codes and plotting codes.","title":"About"},{"location":"C++/cpp/#setup","text":"After checking out the repository, you need to setup ROOT framework and gcc compiler. The current version was compiled using gcc v6.20 and root v6.10.04","title":"Setup"},{"location":"C++/cpp/#samples","text":"For now, the analysis code can be run using samples located in eos: /eos/project/a/atlas-outreach/projects/open-data/OpenDataTuples/","title":"Samples"},{"location":"C++/cpp/#analysis-code","text":"The analysis code is located in the Analysis folder. It will be used to write out histograms for the individual input files which will be used for plotting purposes later. There are currently 7 available analyses stored as \" NNAnalysis \", where NN = WBoson, ZBoson, TTbar, WZDiBoson, ZZDiBoson, HWW, ZPrime Each analysis code contains - the analysis header ( NNAnalysis.h ) which defines the histograms and gives access to the variables stored in the input samples - the histogram header ( NNAnalysisHistograms.h ) which defines the name of output histograms - the analysis code ( NNAnalysis.C ) which makes all the selection and stores the output histograms - the analysis main ( main_NNAnalysis.C ) controls which samples are being used - the output directory ( Output_NNAnalysis ) is where the output histograms (one per each input sample) will be stored First setup the code using: * ./welcome.sh or * source welcome.sh To run the code: * ./run.sh or * source run.sh Shared libraries will be created and the analysis will run over each input sample. Estimated time it takes to run an analysis code: 15 seconds per 1M events To clean all shared libraries: * ./clean.sh or * source clean.sh","title":"Analysis Code"},{"location":"C++/cpp/#plotting","text":"The plotting code is located in the Plotting folder. * Compile the plotting code with the command: make Run the code with: ./plot [WBosonAnalysis, ZBosonAnalysis, TTbarAnalysis, DiBosonAnalysis, HWWAnalysis, ZPrimeAnalysis] [location of OutputDir_AnalysisName] Here you have to choose * 1.) which analysis you will run * 2.) where is the output of the analysis code you produced Examples ./plot ZBosonAnalysis ../Analysis/ZBosonAnalysis/OutputDir_ZBosonAnalysis The plots are saved inside the directory \" histograms \", don't forget to rename in case you run over several analyses Which histograms are being produced? This is controlled by the input file \" HistoList_ANALYSISNAME.txt \" inside list_histos Do you want to add a new plot? just add the name of it in this file (of course it has to exist in the output from the analysis code) In case you changed the Plotting code, clean first: make clean; make Auxiliary: Files.txt contains the name, cross-section, sum of weights and efficiency for each of the MC samples. DO NOT CHANGE","title":"Plotting"},{"location":"C++/cpp/#how-to-add-a-new-variable-and-plot-it","text":"Add in the header ( NNAnalysis.h ) the new histogram: TH1F *h_new = 0; Add in the main analysis code ( NNAnalysis.C ) the calculation of the new variable: float new_variable = jet_n; Add in NNAnalysisHistograms.h in define_histograms(): h_new = new TH1F(\"h_new\", \"Description of the new variable; X axis name ; Y axis name \", number of bins , min bin , max bin); in FillOutputList() GetOutputList()->Add(h_new); in WriteHistograms() h_new->Write(); in FillHistograms() if (s.Contains(\"h_new\")) h_new->Fill(m,w); Now finally add in NNAnalysis.C the connection between the new variable and the new histogram FillHistograms( new_variable, weight, \"h_new\"); where \"new_variable\" is the new variable you calculated in 2. now run the code again over all the samples Go to PlottingCode/list_histos in HistoList_NNAnalysis.txt add one new line: h_new run the plotting code and you will find the new histogram in histograms/h_new.png !","title":"How to add a new variable and plot it"},{"location":"C++/times/","text":"ATLAS Open Data C++ framework for 13 TeV analyses About Z boson (ZBosonAnalysis) 993.55s user 20.04s system 90% cpu 18:44.92 total H->gg (HyyAnalysis) 84.08s user 5.78s system 95% cpu 1:33.77 total H->ZZ ./run.sh 658.76s user 17.76s system 85% cpu 13:12.13 total (ZZDiBosonAnalysis) WZ ./run.sh 678.57s user 17.11s system 63% cpu 18:20.84 total (WZDiBosonAnalysis) TTbar ./run.sh 2770.97s user 58.98s system 88% cpu 53:03.66 total (TTbarAnalysis) W boson ./run.sh 3277.89s user 46.79s system 91% cpu 1:00:28.64 total (WBosonAnalysis) Note Version of ROOT >6.14 give problem with the include \"TProof.h\"","title":"C++ notes"},{"location":"C++/times/#atlas-open-data-c-framework-for-13-tev-analyses","text":"","title":"ATLAS Open Data C++ framework for 13 TeV analyses"},{"location":"C++/times/#about","text":"Z boson (ZBosonAnalysis) 993.55s user 20.04s system 90% cpu 18:44.92 total H->gg (HyyAnalysis) 84.08s user 5.78s system 95% cpu 1:33.77 total H->ZZ ./run.sh 658.76s user 17.76s system 85% cpu 13:12.13 total (ZZDiBosonAnalysis) WZ ./run.sh 678.57s user 17.11s system 63% cpu 18:20.84 total (WZDiBosonAnalysis) TTbar ./run.sh 2770.97s user 58.98s system 88% cpu 53:03.66 total (TTbarAnalysis) W boson ./run.sh 3277.89s user 46.79s system 91% cpu 1:00:28.64 total (WBosonAnalysis) Note Version of ROOT >6.14 give problem with the include \"TProof.h\"","title":"About"},{"location":"GitBook/","text":"Get Started Here we present two methods of online data visualisation. Both are easy to use, but still very powerful. Histogram Analyser A web based tool for fast, cut-based analysis of data. Visualise the data using online histograms. This tool shows how physicists differentiate between physics processes. The signatures of different physics processes can look very different from one another. By applying cuts to data, specific physics processes (signal) can be isolated from the background. The webpage displays nine histograms of variables which can be used to isolate Higgs boson events. Use your cursor to apply selections to a particular variable. The effect on the other variables will be shown immediately. The Histogram Analyser will help you understand the data and the relationship between the signal and background processes. It can simplify and speed-up the selection of cuts, before coding an analysis. Analysis Browser A web based tool for the more advanced user. ROOT browser lets you inspect the datasets more thoroughly. More variables are available for display with ROOTbrowser than Histogram Analyser. You can inspect one or more datasets. Distributions can be displayed for various variables of interest. You can display the distributions and impose your own selections by using the cursor. The ROOT browser can help you understand the data, before you begin writing analysis code. Have a go! Take a look Use the arrows to navigate through this book. Or use the menu displayed on the left to access the chapters directly. If you cannot see the menu, click on the hamburger icon (4 horizontal lines) displayed top left under the \"Open/Close the book\" button.","title":"Get Started"},{"location":"GitBook/#get-started","text":"Here we present two methods of online data visualisation. Both are easy to use, but still very powerful.","title":"Get Started"},{"location":"GitBook/#histogram-analyser","text":"A web based tool for fast, cut-based analysis of data. Visualise the data using online histograms. This tool shows how physicists differentiate between physics processes. The signatures of different physics processes can look very different from one another. By applying cuts to data, specific physics processes (signal) can be isolated from the background. The webpage displays nine histograms of variables which can be used to isolate Higgs boson events. Use your cursor to apply selections to a particular variable. The effect on the other variables will be shown immediately. The Histogram Analyser will help you understand the data and the relationship between the signal and background processes. It can simplify and speed-up the selection of cuts, before coding an analysis.","title":"Histogram Analyser"},{"location":"GitBook/#analysis-browser","text":"A web based tool for the more advanced user. ROOT browser lets you inspect the datasets more thoroughly. More variables are available for display with ROOTbrowser than Histogram Analyser. You can inspect one or more datasets. Distributions can be displayed for various variables of interest. You can display the distributions and impose your own selections by using the cursor. The ROOT browser can help you understand the data, before you begin writing analysis code. Have a go!","title":"Analysis Browser"},{"location":"GitBook/#take-a-look","text":"Use the arrows to navigate through this book. Or use the menu displayed on the left to access the chapters directly. If you cannot see the menu, click on the hamburger icon (4 horizontal lines) displayed top left under the \"Open/Close the book\" button.","title":"Take a look"},{"location":"GitBook/GLOSSARY/","text":"Glossary This is not intended to be an exhaustive glossary. You will find answers to many of your questions by using a search engine. However, here are afew ATLAS physics terms explained to start you off. Detector layout The ATLAS detector has a layout that is typical for a collider detector. There are two types of detector components: tracking detectors, which measure the position of a crossing charged particle with minimal disturbance, and calorimeters, which measure the energy of a particle by total absorption. Travelling from the collision point outwards there exist tracking detectors (inner detector), then calorimeters (electromagnetic and hadronic) and then more tracking detectors (muon spectrometer). The complete ATLAS detector is split into a barrel part, where detector layers are positioned on cylindrical surfaces around the beam axis, and two end-cap parts, where detector layers are positioned in planes of constant z perpendicular to the beam pipe. ATLAS coordinate system The coordinate system of ATLAS is a right-handed coordinate system with the x-axis pointing towards the centre of the LHC tunnel, and the z-axis along the tunnel. The y-axis is slightly tilted with respect to vertical due to the general tilt of the tunnel. Azimuth angle, phi ($$\\phi$$) The azimuthal angle $$\\phi$$ is measured from the $$x$$-axis, around the beam. The ATLAS detector design is symmetrical in phi. Pseudorapidity (eta) The pseudorapidity describes the angle of a particle relative to the beam axis. Opening angle The opening angle (also called angular separation) between physics objects e.g.lepton pair, can be important in understanding or identifying different physics processes. It is calculated as a function of eta and phi. Monte-Carlo generators Monte-Carlo generators are programs used for simulating data. Good Run List Good run lists are the way to select good data samples for physics analysis. There are a number of ways the data may not be good e.g the LHC is not in stable-beam mode, the magnets are off, some of the sub-detectors are switched off. Jet Jets are the dominant final state objects of high-energy proton-proton interactions at the LHC. They are key ingredients for many physics measurements and for searches for new phenomena. Jets are observed as groups of topologically-related energy deposits in the ATLAS calorimeters, most of which are associated with tracks of charged particles as measured in the inner detector. They are reconstructed and calibrated using a combination of methods based on simulation and data-driven techniques. Good, bad and ugly jets Jet cleaning criteria have been developed in order to identify fake jets which arise due to noise or to out-of-time energy depositions. Jets failing these criteria are flagged as either \u201cbad\u201d, likely to be fake, or \u201cugly\u201d, likely to be mismeasured due to falling into less well instrumented regions. Jet Vertex Fraction (JVF) The Jet Vertex Fraction can be used to select jets with a high fraction of track energy originating from the selected primary vertex. It can be used to suppress pile-up jets. Isolation Isolation is important because it indicates where the lepton stems from. For example, an isolated electron is likely to originate from $$Z$$ boson, $$W$$ boson or $$\\tau$$-lepton. In contrast, a non-isolated electron is likely to originate from $$b$$-hadron or $$c$$-hadron decays. $$p_{T}$$ The term $$p_{T}$$ stands for transverse momentum, the component of momentum perpendicular to the beam line. In proton-proton collisions the overall momentum along the beamline is not known. This is because protons are composite particles consisting of many partons (quarks and gluons). When two protons collide it is actually the partons that interact. Each of the partons carries an unknown fraction of the protons momentum. So their exact momentum along the beamline is unknown. We only know that the overall momentum perpendicular to the beamline is zero before the collision. Thus, transverse momentum is the most important momentum variable in a proton-proton collision. Event An event is a snapshot of a collision in the LHC. Energy is equivalent to mass, so highly energetic collisions can create particles more massive than those involved in the collisions (protons, in the case of the LHC). These massive particles quickly decay into lighter stable particles. Physicists study the decay products of collisions to determine what particles were created in the events. Signal High-energy physicists, whether making a precise measurement of a known quantity or searching for hypothetical new particles, select from the sample of events recorded those with characteristics resembling those of the desired signal, while rejecting as many non-signal events (background) as possible. Background Data contains both signal and background events. Background events are rejected so that the desired physics processes can be observed. Fundamental Particles Fundamental particles are the building blocks of matter as they are all indivisible. All other particles are therefore a combination of the fundamental particles. Fundamental Forces The fundamental forces, explain the interactions between particles in our universe. These forces are gravity, electromagnetism, the strong and the weak force. Electromagnetism and the weak force are linked through the electroweak theory. Fermion A subatomic particle, such as a nucleon, which has half-integral spin and follows a statistical description given by Fermi and Dirac. Boson A subatomic particle, such as a photon, which has zero or integral spin and follows a statistical description given by S.N. Bose and Einstein. Channel The decay channel signifies a certain route a physics process has taken. For example, the $$W$$ boson may decay to either a pair of hadrons or a pair of leptons. The signature for these W bosons in the detector are therefore either two hadrons or two leptons. These may be referred to the hadronic and leptonic channel of the W boson decay, respectively. If we want to study an object we cannot directly observe, e.g. a W boson, we must find a channel that is easily accessible. In general, decays to leptons are easiest to spot but are not as abundant as hadronic decays. Branching fraction In general, a particle can decay in several modes or decay channels. For example, a Z boson can decay into a pair of neutrinos, a pair of charged leptons, or a pair of quarks (i.e., all the standard model fermions lighter than half the $$Z$$ mass). The probability for a Z to decay into a neutrino pair is about 20%, into a pair of charged leptons (electrons, muons, or taus) is about 10%, and into a pair of quarks (u,d,c,s,b) is about 70%. These probabilities are called branching fractions. Electron Volt (eV) One electron volt is equal to ~1.6 X 10^-19 joules. MeV (10^6) and TeV (10^12) are units of energy used in particle physics. 1 TeV is about the energy of motion of a flying mosquito. Antiparticle Antimatter: A particle and its antiparticle have the same mass as one another, but opposite electric charge and other quantum numbers. A collision between any particle and its antiparticle partner leads to their mutual annihilation, giving rise to various proportions of photons, neutrinos, and sometimes less massive particle\u2013antiparticle pairs. Parton Distribution Functions The momentum distribution functions of the partons (quarks and gluons) within the proton are called Parton Distribution Functions. Vectorial sum A vectorial sum is the result of adding two or more vectors together via vector addition.","title":"Glossary"},{"location":"GitBook/GLOSSARY/#glossary","text":"This is not intended to be an exhaustive glossary. You will find answers to many of your questions by using a search engine. However, here are afew ATLAS physics terms explained to start you off.","title":"Glossary"},{"location":"GitBook/GLOSSARY/#detector-layout","text":"The ATLAS detector has a layout that is typical for a collider detector. There are two types of detector components: tracking detectors, which measure the position of a crossing charged particle with minimal disturbance, and calorimeters, which measure the energy of a particle by total absorption. Travelling from the collision point outwards there exist tracking detectors (inner detector), then calorimeters (electromagnetic and hadronic) and then more tracking detectors (muon spectrometer). The complete ATLAS detector is split into a barrel part, where detector layers are positioned on cylindrical surfaces around the beam axis, and two end-cap parts, where detector layers are positioned in planes of constant z perpendicular to the beam pipe.","title":"Detector layout"},{"location":"GitBook/GLOSSARY/#atlas-coordinate-system","text":"The coordinate system of ATLAS is a right-handed coordinate system with the x-axis pointing towards the centre of the LHC tunnel, and the z-axis along the tunnel. The y-axis is slightly tilted with respect to vertical due to the general tilt of the tunnel.","title":"ATLAS coordinate system"},{"location":"GitBook/GLOSSARY/#azimuth-angle-phi-phi","text":"The azimuthal angle $$\\phi$$ is measured from the $$x$$-axis, around the beam. The ATLAS detector design is symmetrical in phi.","title":"Azimuth angle, phi ($$\\phi$$)"},{"location":"GitBook/GLOSSARY/#pseudorapidity-eta","text":"The pseudorapidity describes the angle of a particle relative to the beam axis.","title":"Pseudorapidity (eta)"},{"location":"GitBook/GLOSSARY/#opening-angle","text":"The opening angle (also called angular separation) between physics objects e.g.lepton pair, can be important in understanding or identifying different physics processes. It is calculated as a function of eta and phi.","title":"Opening angle"},{"location":"GitBook/GLOSSARY/#monte-carlo-generators","text":"Monte-Carlo generators are programs used for simulating data.","title":"Monte-Carlo generators"},{"location":"GitBook/GLOSSARY/#good-run-list","text":"Good run lists are the way to select good data samples for physics analysis. There are a number of ways the data may not be good e.g the LHC is not in stable-beam mode, the magnets are off, some of the sub-detectors are switched off.","title":"Good Run List"},{"location":"GitBook/GLOSSARY/#jet","text":"Jets are the dominant final state objects of high-energy proton-proton interactions at the LHC. They are key ingredients for many physics measurements and for searches for new phenomena. Jets are observed as groups of topologically-related energy deposits in the ATLAS calorimeters, most of which are associated with tracks of charged particles as measured in the inner detector. They are reconstructed and calibrated using a combination of methods based on simulation and data-driven techniques.","title":"Jet"},{"location":"GitBook/GLOSSARY/#good-bad-and-ugly-jets","text":"Jet cleaning criteria have been developed in order to identify fake jets which arise due to noise or to out-of-time energy depositions. Jets failing these criteria are flagged as either \u201cbad\u201d, likely to be fake, or \u201cugly\u201d, likely to be mismeasured due to falling into less well instrumented regions.","title":"Good, bad and ugly jets"},{"location":"GitBook/GLOSSARY/#jet-vertex-fraction-jvf","text":"The Jet Vertex Fraction can be used to select jets with a high fraction of track energy originating from the selected primary vertex. It can be used to suppress pile-up jets.","title":"Jet Vertex Fraction (JVF)"},{"location":"GitBook/GLOSSARY/#isolation","text":"Isolation is important because it indicates where the lepton stems from. For example, an isolated electron is likely to originate from $$Z$$ boson, $$W$$ boson or $$\\tau$$-lepton. In contrast, a non-isolated electron is likely to originate from $$b$$-hadron or $$c$$-hadron decays.","title":"Isolation"},{"location":"GitBook/GLOSSARY/#p_t","text":"The term $$p_{T}$$ stands for transverse momentum, the component of momentum perpendicular to the beam line. In proton-proton collisions the overall momentum along the beamline is not known. This is because protons are composite particles consisting of many partons (quarks and gluons). When two protons collide it is actually the partons that interact. Each of the partons carries an unknown fraction of the protons momentum. So their exact momentum along the beamline is unknown. We only know that the overall momentum perpendicular to the beamline is zero before the collision. Thus, transverse momentum is the most important momentum variable in a proton-proton collision.","title":"$$p_{T}$$"},{"location":"GitBook/GLOSSARY/#event","text":"An event is a snapshot of a collision in the LHC. Energy is equivalent to mass, so highly energetic collisions can create particles more massive than those involved in the collisions (protons, in the case of the LHC). These massive particles quickly decay into lighter stable particles. Physicists study the decay products of collisions to determine what particles were created in the events.","title":"Event"},{"location":"GitBook/GLOSSARY/#signal","text":"High-energy physicists, whether making a precise measurement of a known quantity or searching for hypothetical new particles, select from the sample of events recorded those with characteristics resembling those of the desired signal, while rejecting as many non-signal events (background) as possible.","title":"Signal"},{"location":"GitBook/GLOSSARY/#background","text":"Data contains both signal and background events. Background events are rejected so that the desired physics processes can be observed.","title":"Background"},{"location":"GitBook/GLOSSARY/#fundamental-particles","text":"Fundamental particles are the building blocks of matter as they are all indivisible. All other particles are therefore a combination of the fundamental particles.","title":"Fundamental Particles"},{"location":"GitBook/GLOSSARY/#fundamental-forces","text":"The fundamental forces, explain the interactions between particles in our universe. These forces are gravity, electromagnetism, the strong and the weak force. Electromagnetism and the weak force are linked through the electroweak theory.","title":"Fundamental Forces"},{"location":"GitBook/GLOSSARY/#fermion","text":"A subatomic particle, such as a nucleon, which has half-integral spin and follows a statistical description given by Fermi and Dirac.","title":"Fermion"},{"location":"GitBook/GLOSSARY/#boson","text":"A subatomic particle, such as a photon, which has zero or integral spin and follows a statistical description given by S.N. Bose and Einstein.","title":"Boson"},{"location":"GitBook/GLOSSARY/#channel","text":"The decay channel signifies a certain route a physics process has taken. For example, the $$W$$ boson may decay to either a pair of hadrons or a pair of leptons. The signature for these W bosons in the detector are therefore either two hadrons or two leptons. These may be referred to the hadronic and leptonic channel of the W boson decay, respectively. If we want to study an object we cannot directly observe, e.g. a W boson, we must find a channel that is easily accessible. In general, decays to leptons are easiest to spot but are not as abundant as hadronic decays.","title":"Channel"},{"location":"GitBook/GLOSSARY/#branching-fraction","text":"In general, a particle can decay in several modes or decay channels. For example, a Z boson can decay into a pair of neutrinos, a pair of charged leptons, or a pair of quarks (i.e., all the standard model fermions lighter than half the $$Z$$ mass). The probability for a Z to decay into a neutrino pair is about 20%, into a pair of charged leptons (electrons, muons, or taus) is about 10%, and into a pair of quarks (u,d,c,s,b) is about 70%. These probabilities are called branching fractions.","title":"Branching fraction"},{"location":"GitBook/GLOSSARY/#electron-volt-ev","text":"One electron volt is equal to ~1.6 X 10^-19 joules. MeV (10^6) and TeV (10^12) are units of energy used in particle physics. 1 TeV is about the energy of motion of a flying mosquito.","title":"Electron Volt (eV)"},{"location":"GitBook/GLOSSARY/#antiparticle","text":"Antimatter: A particle and its antiparticle have the same mass as one another, but opposite electric charge and other quantum numbers. A collision between any particle and its antiparticle partner leads to their mutual annihilation, giving rise to various proportions of photons, neutrinos, and sometimes less massive particle\u2013antiparticle pairs.","title":"Antiparticle"},{"location":"GitBook/GLOSSARY/#parton-distribution-functions","text":"The momentum distribution functions of the partons (quarks and gluons) within the proton are called Parton Distribution Functions.","title":"Parton Distribution Functions"},{"location":"GitBook/GLOSSARY/#vectorial-sum","text":"A vectorial sum is the result of adding two or more vectors together via vector addition.","title":"Vectorial sum"},{"location":"GitBook/SUMMARY/","text":"Summary Get Started The Higgs Boson ATLAS events Analyses Data and Simulated Data Histogram Analyser Histogram Analyser 2 Separate Signals Find the Higgs Analysis browser ROOTbrowser datasets ROOTbrowser Variable Names ROOTbrowser final plots Glossary Particle Physics Masterclasses","title":"GitBook"},{"location":"GitBook/SUMMARY/#summary","text":"Get Started The Higgs Boson ATLAS events Analyses Data and Simulated Data Histogram Analyser Histogram Analyser 2 Separate Signals Find the Higgs Analysis browser ROOTbrowser datasets ROOTbrowser Variable Names ROOTbrowser final plots Glossary Particle Physics Masterclasses","title":"Summary"},{"location":"GitBook/analyses/","text":"Analyses Histogram Analyser focusses on four physics processes; the signal Higgs boson process $$H\\rightarrow W^+W^-$$ and three background processes $$WW$$, $$t\\bar t$$ and $$Z$$. Let's take a look at these processes. $$H\\rightarrow W^+W^-$$ The Higgs boson is an essential ingredient of the Standard Model of particle physics, the theory that describes all known elementary particles and their interactions. The Higgs boson interacts with all Standard Model elementary particles having mass. Thus, there are different ways to produce a Higgs boson, and different ways for a Higgs boson to decay to other particles. One of the most likely ways a Higgs boson will decay is into a pair of $$W$$ bosons. This happens about 21% of the time for a Higgs boson with a mass of 125 GeV. The $$W$$ bosons can subsequently decay either into a quark-antiquark ($$q \\bar q$$), a lepton-antineutrino ($$\\ell^- \\bar\\nu$$), or an antilepton-neutrino ($$\\ell^+\\nu$$) pair. The signal process in Histogram Analyser is the Higgs boson decaying into two $$W$$ bosons which subsequently decay into leptons ($$\\ell$$) and neutrinos ($$\\nu$$): $$H\\rightarrow W^+W^-\\rightarrow \\ell^+ \\ell^-\\nu \\bar\\nu$$ (lepton = electron or muon in this case). A key feature, or signature of this signal process, is an isolated high-$$p_\\text{T}$$ lepton. The term $$p_\\text{T}$$ stands for transverse momentum, the component of momentum perpendicular to the beam line (colliding protons). Unfortunately, the main background processes also contain isolated high-$$p_\\text{T}$$ leptons from $$W$$ or $$Z$$ boson decays. Often physicists refer to a particle and its antiparticle collectively by just the particle's name. So, when we talk about quarks we mean quarks and antiquarks. Similarly for leptons and antileptons, neutrinos and antineutrinos. It is a shorthand that physicists adopt for brevity. $$WW$$ The $$W$$ boson is a fundamental particle. Together with the $$Z$$ boson, it is responsible for the weak force, one of four fundamental forces that govern the behaviour of matter in our universe. $$W$$ boson pair production occurs via quark\u2013antiquark annihilation: $$q\\bar q \\rightarrow W^+W^-$$ diphoton process: $$\\gamma\\gamma\\rightarrow W^+W^-$$ gluon fusion: $$gg\\rightarrow W^+W^-$$ $$W$$ boson pair production is an important process for checks of the gauge structure of the Standard Model and the search for new physics . It is an irreducible background for many Higgs boson studies and new physics searches. $$W$$ bosons can decay either leptonically : into an electron or muon and neutrino. hadronically : into an up-type quark and a down-type quark. Leptonic $$W$$ boson decays are characterised by the presence of a highly energetic isolated lepton and large missing transverse momentum. Missing transverse momentum can occur due to neutrinos escaping detection. Hadronic $$W$$ boson decays lead to the presence of two jets due to the two quarks. Only leptonic decays are considered in Histogram Analyser. The $$WW$$ process will thus be seen in the electron-electron (ee), muon-muon (mm) and electron-muon (em) channel. Final states with leptons and missing energy are typical for many new physics models , supersymmetry is a classic example, but also for many Standard Model processes. Understanding the Standard Model processes possessing multiple leptons and missing energy is crucial in the quest to discover or rule out new models. $$t\\bar t$$ Monte Carlo data simulation generators, QCD models and parton distribution functions are very reliant on theoretical models. Due to the very high energy of top pairs, top pair data can verify important areas of the aforementioned models and test how good the models are. Top quark pair production is an important background in various Higgs boson analyses and beyond the Standard Model searches. It is therefore crucial to understand this process in detail. Top quarks decay with close to 100% probability into a W boson and a bottom quark. The $$W$$ in turns decays equally to a pair of leptons or a pair of quarks. Since there are three colours for every quark the $$W$$ boson decay to two jets is three times more probable than its decay to an electron or a muon. The two bottom-quarks from the two top-quark decays will be seen as two jets in the final state. Algorithms are used to identify these jets. Jets thought to originate from $$b$$-quarks are called b-tagged jets. Additional jets in $$t \\bar t $$ events can originate from gluon radiation. Since almost all the energy of the decay products is derived from the rest energy of the top/anti-top pair, finding the total energy of all the decay products and summing should yield the rest energy (and therefore mass) of the particles that have decayed. But the detector can only \"see\" the charged particles. It misses the neutrinos produced in the decay. $$Z$$ The $$W$$ and $$Z$$ bosons are together known as the weak or intermediate vector bosons. At the LHC, $$Z$$ bosons are produced by: Drell-Yan : $$ q \\bar q \\rightarrow Z/\\gamma^* \\rightarrow \\mu^+\\mu^-$$(65%). A quark of one proton and an antiquark of another proton annihilate, creating a virtual photon or $$Z$$ boson which then decays into a pair of oppositely-charged leptons. Quark gluon scattering : $$qg \\rightarrow qZ/\u03b3^* \\rightarrow q\\mu^+\\mu^\u2212$$ (35%). A quark and a gluon interact and the quark radiates a virtual photon or $$Z$$ boson which then decays into a pair of oppositely-charged leptons. A $$Z$$ boson then decays into a: quark-antiquark pair (70%). These appear as jets. If the jets are identified as originating from $$b$$-quarks they will be b-tagged. neutrino-antineutrino pair (20%). Neutrinos do not interact and so are very difficult to detect. This neutrino decay mode can sometimes be identified by missing transverse momentum. lepton-antilepton pairs (10%). The three lepton-pair types are equally probable, electron-positron, muon-antimuon, and tau-antitau pairs. A $$Z$$ boson is neutral and so the sum of the charges of its decay products must be zero. In Histogram Analyser the lepton-antilepton pair production can be studied in the electron-electron (ee) and muon-muon (mm) channel. Decays to taus are not considered in Histogram Analyser since lectrons and muons are much easier to measure than taus.","title":"Analyses"},{"location":"GitBook/analyses/#analyses","text":"Histogram Analyser focusses on four physics processes; the signal Higgs boson process $$H\\rightarrow W^+W^-$$ and three background processes $$WW$$, $$t\\bar t$$ and $$Z$$. Let's take a look at these processes.","title":"Analyses"},{"location":"GitBook/analyses/#hrightarrow-ww-","text":"The Higgs boson is an essential ingredient of the Standard Model of particle physics, the theory that describes all known elementary particles and their interactions. The Higgs boson interacts with all Standard Model elementary particles having mass. Thus, there are different ways to produce a Higgs boson, and different ways for a Higgs boson to decay to other particles. One of the most likely ways a Higgs boson will decay is into a pair of $$W$$ bosons. This happens about 21% of the time for a Higgs boson with a mass of 125 GeV. The $$W$$ bosons can subsequently decay either into a quark-antiquark ($$q \\bar q$$), a lepton-antineutrino ($$\\ell^- \\bar\\nu$$), or an antilepton-neutrino ($$\\ell^+\\nu$$) pair. The signal process in Histogram Analyser is the Higgs boson decaying into two $$W$$ bosons which subsequently decay into leptons ($$\\ell$$) and neutrinos ($$\\nu$$): $$H\\rightarrow W^+W^-\\rightarrow \\ell^+ \\ell^-\\nu \\bar\\nu$$ (lepton = electron or muon in this case). A key feature, or signature of this signal process, is an isolated high-$$p_\\text{T}$$ lepton. The term $$p_\\text{T}$$ stands for transverse momentum, the component of momentum perpendicular to the beam line (colliding protons). Unfortunately, the main background processes also contain isolated high-$$p_\\text{T}$$ leptons from $$W$$ or $$Z$$ boson decays. Often physicists refer to a particle and its antiparticle collectively by just the particle's name. So, when we talk about quarks we mean quarks and antiquarks. Similarly for leptons and antileptons, neutrinos and antineutrinos. It is a shorthand that physicists adopt for brevity.","title":"$$H\\rightarrow W^+W^-$$"},{"location":"GitBook/analyses/#ww","text":"The $$W$$ boson is a fundamental particle. Together with the $$Z$$ boson, it is responsible for the weak force, one of four fundamental forces that govern the behaviour of matter in our universe. $$W$$ boson pair production occurs via quark\u2013antiquark annihilation: $$q\\bar q \\rightarrow W^+W^-$$ diphoton process: $$\\gamma\\gamma\\rightarrow W^+W^-$$ gluon fusion: $$gg\\rightarrow W^+W^-$$ $$W$$ boson pair production is an important process for checks of the gauge structure of the Standard Model and the search for new physics . It is an irreducible background for many Higgs boson studies and new physics searches. $$W$$ bosons can decay either leptonically : into an electron or muon and neutrino. hadronically : into an up-type quark and a down-type quark. Leptonic $$W$$ boson decays are characterised by the presence of a highly energetic isolated lepton and large missing transverse momentum. Missing transverse momentum can occur due to neutrinos escaping detection. Hadronic $$W$$ boson decays lead to the presence of two jets due to the two quarks. Only leptonic decays are considered in Histogram Analyser. The $$WW$$ process will thus be seen in the electron-electron (ee), muon-muon (mm) and electron-muon (em) channel. Final states with leptons and missing energy are typical for many new physics models , supersymmetry is a classic example, but also for many Standard Model processes. Understanding the Standard Model processes possessing multiple leptons and missing energy is crucial in the quest to discover or rule out new models.","title":"$$WW$$"},{"location":"GitBook/analyses/#tbar-t","text":"Monte Carlo data simulation generators, QCD models and parton distribution functions are very reliant on theoretical models. Due to the very high energy of top pairs, top pair data can verify important areas of the aforementioned models and test how good the models are. Top quark pair production is an important background in various Higgs boson analyses and beyond the Standard Model searches. It is therefore crucial to understand this process in detail. Top quarks decay with close to 100% probability into a W boson and a bottom quark. The $$W$$ in turns decays equally to a pair of leptons or a pair of quarks. Since there are three colours for every quark the $$W$$ boson decay to two jets is three times more probable than its decay to an electron or a muon. The two bottom-quarks from the two top-quark decays will be seen as two jets in the final state. Algorithms are used to identify these jets. Jets thought to originate from $$b$$-quarks are called b-tagged jets. Additional jets in $$t \\bar t $$ events can originate from gluon radiation. Since almost all the energy of the decay products is derived from the rest energy of the top/anti-top pair, finding the total energy of all the decay products and summing should yield the rest energy (and therefore mass) of the particles that have decayed. But the detector can only \"see\" the charged particles. It misses the neutrinos produced in the decay.","title":"$$t\\bar t$$"},{"location":"GitBook/analyses/#z","text":"The $$W$$ and $$Z$$ bosons are together known as the weak or intermediate vector bosons. At the LHC, $$Z$$ bosons are produced by: Drell-Yan : $$ q \\bar q \\rightarrow Z/\\gamma^* \\rightarrow \\mu^+\\mu^-$$(65%). A quark of one proton and an antiquark of another proton annihilate, creating a virtual photon or $$Z$$ boson which then decays into a pair of oppositely-charged leptons. Quark gluon scattering : $$qg \\rightarrow qZ/\u03b3^* \\rightarrow q\\mu^+\\mu^\u2212$$ (35%). A quark and a gluon interact and the quark radiates a virtual photon or $$Z$$ boson which then decays into a pair of oppositely-charged leptons. A $$Z$$ boson then decays into a: quark-antiquark pair (70%). These appear as jets. If the jets are identified as originating from $$b$$-quarks they will be b-tagged. neutrino-antineutrino pair (20%). Neutrinos do not interact and so are very difficult to detect. This neutrino decay mode can sometimes be identified by missing transverse momentum. lepton-antilepton pairs (10%). The three lepton-pair types are equally probable, electron-positron, muon-antimuon, and tau-antitau pairs. A $$Z$$ boson is neutral and so the sum of the charges of its decay products must be zero. In Histogram Analyser the lepton-antilepton pair production can be studied in the electron-electron (ee) and muon-muon (mm) channel. Decays to taus are not considered in Histogram Analyser since lectrons and muons are much easier to measure than taus.","title":"$$Z$$"},{"location":"GitBook/animated_atlas_events/","text":"Animated ATLAS events Click on the link below to see an ATLAS animation of a real event display at 7 TeV on March 30th. https://cds.cern.ch/video/CERN-VIDEORUSH-2010-021","title":"Animated ATLAS events"},{"location":"GitBook/animated_atlas_events/#animated-atlas-events","text":"Click on the link below to see an ATLAS animation of a real event display at 7 TeV on March 30th. https://cds.cern.ch/video/CERN-VIDEORUSH-2010-021","title":"Animated ATLAS events"},{"location":"GitBook/atlas_at_cern/","text":"ATLAS at CERN Discover more about ATLAS and the LHC at CERN: ATLAS the Experiment The Detector The Physics Physics Results","title":"ATLAS at CERN"},{"location":"GitBook/atlas_at_cern/#atlas-at-cern","text":"Discover more about ATLAS and the LHC at CERN: ATLAS the Experiment The Detector The Physics Physics Results","title":"ATLAS at CERN"},{"location":"GitBook/atlas_events/","text":"ATLAS events Beams of protons are accelerated around the Large Hadron Collider (LHC) and are brought to collision at the centre of the ATLAS detector. The collisions produce debris in the form of new particles which fly out in all directions. Over a billion particle interactions take place in the ATLAS detector every second. The protons within the two beams are grouped in bunches which are squeezed down in size to increase the chances of a collision. In the released data, the bunches crossed every 50 ns. There were about 30 collisions on average per bunch-crossing . An event is the data resulting from a particular bunch-crossing. Pile-up is defined as the average number of particle interactions per bunch-crossing. It is directly correlated with the instantaneous luminosity. Luminosity is one of the most important parameters of the LHC. The higher the luminosity, the more data the experiments can gather to allow them to observe rare processes. However, increasing luminosity increases pile-up. This presents a challenge for physics analyses as it makes successfully identify collisions of interest harder. The primary vertex is defined as the inelastic collision of two protons with the highest overall transverse momentum. In a typical collision event, several vertices along the beam are produced. It is important to correctly identify them to associate the observed particles to the correct vertex to suppress the effects from pile-up. The many low transverse momentum proton-proton interactions occuring are called minimum bias events. The above event display shows a candidate $$Z$$ boson decaying into two muons with 11 reconstructed vertices. This event was recorded on April 24th and is typical for the 2011 environment with high pile-up. The reconstruction of vertices is important for many physics studies. This includes searches for new particles, identifying jets containing $$b$$-quarks or taus, and reconstruction of exclusive $$b$$-quark decays.","title":"ATLAS events"},{"location":"GitBook/atlas_events/#atlas-events","text":"Beams of protons are accelerated around the Large Hadron Collider (LHC) and are brought to collision at the centre of the ATLAS detector. The collisions produce debris in the form of new particles which fly out in all directions. Over a billion particle interactions take place in the ATLAS detector every second. The protons within the two beams are grouped in bunches which are squeezed down in size to increase the chances of a collision. In the released data, the bunches crossed every 50 ns. There were about 30 collisions on average per bunch-crossing . An event is the data resulting from a particular bunch-crossing. Pile-up is defined as the average number of particle interactions per bunch-crossing. It is directly correlated with the instantaneous luminosity. Luminosity is one of the most important parameters of the LHC. The higher the luminosity, the more data the experiments can gather to allow them to observe rare processes. However, increasing luminosity increases pile-up. This presents a challenge for physics analyses as it makes successfully identify collisions of interest harder. The primary vertex is defined as the inelastic collision of two protons with the highest overall transverse momentum. In a typical collision event, several vertices along the beam are produced. It is important to correctly identify them to associate the observed particles to the correct vertex to suppress the effects from pile-up. The many low transverse momentum proton-proton interactions occuring are called minimum bias events. The above event display shows a candidate $$Z$$ boson decaying into two muons with 11 reconstructed vertices. This event was recorded on April 24th and is typical for the 2011 environment with high pile-up. The reconstruction of vertices is important for many physics studies. This includes searches for new particles, identifying jets containing $$b$$-quarks or taus, and reconstruction of exclusive $$b$$-quark decays.","title":"ATLAS events"},{"location":"GitBook/data-and-simulated-data/","text":"Data and Simulated Data Data The ATLAS collaboration has released 1 inverse femtobarn of data. One inverse femtobarn corresponds to approximately 100 trillion proton-proton collisions. The ATLAS datasets are available on this website and on the CERN open data portal . Simulated data Simulated data, commonly named Monte Carlo (MC), are a key feature for the LHC experiments. These events are simulated using current theoretical models and are used to compare theory with real data. The full simulation requires the following steps Event generation : Hadronic final states using the proton-proton collisions are generated using programs relying on theoretical calculations, phenomenological models and experimental inputs. Detector Simulation : Interaction of the generated particles inside the ATLAS detector is simulated. Digitisation : The detector response is derived from the particle interactions and it is written in a format compatible with the real output of the detector. In addition, because of the high rate of collisions in the LHC, digitised signals from several simulated events can be piled-up to create samples with a realistic experimental background. Reconstruction : Particle trajectories and energies from the detector are reconstructed. Such final samples are used by the physicists. Comparing real data and simulated data Real data and simulated data do not always agree. This can be due to various reasons, such as the conditions not being exactly the same e.g. Energy, pile-up. not all background processes are included in the simulated data, the physics has not been exactly modeled by the theory. If the data and simulated data does not agree, it is important that physicists understand why.","title":"Data and Simulated Data"},{"location":"GitBook/data-and-simulated-data/#data-and-simulated-data","text":"","title":"Data and Simulated Data"},{"location":"GitBook/data-and-simulated-data/#data","text":"The ATLAS collaboration has released 1 inverse femtobarn of data. One inverse femtobarn corresponds to approximately 100 trillion proton-proton collisions. The ATLAS datasets are available on this website and on the CERN open data portal .","title":"Data"},{"location":"GitBook/data-and-simulated-data/#simulated-data","text":"Simulated data, commonly named Monte Carlo (MC), are a key feature for the LHC experiments. These events are simulated using current theoretical models and are used to compare theory with real data.","title":"Simulated data"},{"location":"GitBook/data-and-simulated-data/#the-full-simulation-requires-the-following-steps","text":"Event generation : Hadronic final states using the proton-proton collisions are generated using programs relying on theoretical calculations, phenomenological models and experimental inputs. Detector Simulation : Interaction of the generated particles inside the ATLAS detector is simulated. Digitisation : The detector response is derived from the particle interactions and it is written in a format compatible with the real output of the detector. In addition, because of the high rate of collisions in the LHC, digitised signals from several simulated events can be piled-up to create samples with a realistic experimental background. Reconstruction : Particle trajectories and energies from the detector are reconstructed. Such final samples are used by the physicists.","title":"The full simulation requires the following steps"},{"location":"GitBook/data-and-simulated-data/#comparing-real-data-and-simulated-data","text":"Real data and simulated data do not always agree. This can be due to various reasons, such as the conditions not being exactly the same e.g. Energy, pile-up. not all background processes are included in the simulated data, the physics has not been exactly modeled by the theory. If the data and simulated data does not agree, it is important that physicists understand why.","title":"Comparing real data and simulated data"},{"location":"GitBook/find_the_higgs_2/","text":"Example: Find the Higgs Follow the steps of a real ATLAS analysis using Histogram Analyser $$H\\rightarrow W^+W^- \\rightarrow \\ell^+ \\ell^-\\nu \\bar \\nu$$ ($$\\ell$$ = lepton = electron or muon) We are looking for a Higgs boson which decays into two $$W$$ bosons which subsequently decay into leptons and neutrinos. The major background contributions to the search in this decay mode are top (top quark pair and W+top quark), $$WW$$ and $$Z$$+jets events. Use the cursor to implement the following cuts, one by one. As you apply the cuts, you should see the distributions changing. Try to understand why each of the distributions change. Think of the physics motivating the cuts. To clear your selection on a specific histogram click on the white background within the histogram area. To clear all your selections click on \"Histogram Analyser\" under Get Started in the main top menu. Now let's try to separate the signal from the background using Histogram Analyser Higgs boson + 0 jet We want to select events which contain two leptons, high missing transverse momentum and no jets. Select: Number of Jets = 0 : We have decided this analysis is specifically with zero jets. Reconstructed Dilepton Mass < 75 GeV : The $$Z$$ events are the major background in this analysis. The $$Z$$ boson has a mass of 91 GeV, which is reconstructed from the mass of the two leptons. Requiring Reconstructed Dilepton Mass to be less than 75 GeV removes over 90 % of the Z events. Total Lepton Transverse Momentum > 30 GeV : For $$Z$$ boson events, the total lepton transverse momentum peaks at zero since the transverse momenta of both leptons cancel each other. For $$H\\rightarrow WW$$, the opening angle between leptons tends to be small, so the total lepton transverse momentum tends to be greater than zero. Missing Transverse Momentum > 40 GeV : This cut should remove $$Z$$ background since there tends to be little missing transverse in $$Z$$ events. $$Z$$ boson decays to charged leptons do not have any neutrinos in the final state while the other processes do. Opening Angle between Leptons < 80 : We know that the opening angle between leptons for $$H\\rightarrow WW$$ tends to be small whereas for Z events the opening angle tends to be large. The dominant background after all these cuts in the Higgs boson + 0 jet channel comes from $$WW$$ and $$Z$$+jets. 3 Higgs events are identified, yielding a significance of 0.277 Higgs boson + 1 jet Select: Number of Jets = 1 no b-tagged jets electron-muon channel only Reconstructed Dilepton Mass < 70 GeV Total Lepton Transverse Momentum > 30 GeV Opening angle between leptons < 80 The dominant background after all these cuts in the Higgs boson + 1 jet channel comes from $$WW$$ and top pair production. 2 Higgs events are identified, yielding a significance of 0.517. Have a go yourself! Perhaps try the $$H\\rightarrow W^+W^-$$ + 0 jet, but separate it into leptonic channels and tune the cuts to maximise the number of $$H\\rightarrow W^+W^-$$ events with maximum significance. Or try something completely different...","title":"Example: Find the Higgs"},{"location":"GitBook/find_the_higgs_2/#example-find-the-higgs","text":"Follow the steps of a real ATLAS analysis using Histogram Analyser $$H\\rightarrow W^+W^- \\rightarrow \\ell^+ \\ell^-\\nu \\bar \\nu$$ ($$\\ell$$ = lepton = electron or muon) We are looking for a Higgs boson which decays into two $$W$$ bosons which subsequently decay into leptons and neutrinos. The major background contributions to the search in this decay mode are top (top quark pair and W+top quark), $$WW$$ and $$Z$$+jets events. Use the cursor to implement the following cuts, one by one. As you apply the cuts, you should see the distributions changing. Try to understand why each of the distributions change. Think of the physics motivating the cuts. To clear your selection on a specific histogram click on the white background within the histogram area. To clear all your selections click on \"Histogram Analyser\" under Get Started in the main top menu. Now let's try to separate the signal from the background using Histogram Analyser","title":"Example: Find the Higgs"},{"location":"GitBook/find_the_higgs_2/#higgs-boson-0-jet","text":"We want to select events which contain two leptons, high missing transverse momentum and no jets. Select: Number of Jets = 0 : We have decided this analysis is specifically with zero jets. Reconstructed Dilepton Mass < 75 GeV : The $$Z$$ events are the major background in this analysis. The $$Z$$ boson has a mass of 91 GeV, which is reconstructed from the mass of the two leptons. Requiring Reconstructed Dilepton Mass to be less than 75 GeV removes over 90 % of the Z events. Total Lepton Transverse Momentum > 30 GeV : For $$Z$$ boson events, the total lepton transverse momentum peaks at zero since the transverse momenta of both leptons cancel each other. For $$H\\rightarrow WW$$, the opening angle between leptons tends to be small, so the total lepton transverse momentum tends to be greater than zero. Missing Transverse Momentum > 40 GeV : This cut should remove $$Z$$ background since there tends to be little missing transverse in $$Z$$ events. $$Z$$ boson decays to charged leptons do not have any neutrinos in the final state while the other processes do. Opening Angle between Leptons < 80 : We know that the opening angle between leptons for $$H\\rightarrow WW$$ tends to be small whereas for Z events the opening angle tends to be large. The dominant background after all these cuts in the Higgs boson + 0 jet channel comes from $$WW$$ and $$Z$$+jets. 3 Higgs events are identified, yielding a significance of 0.277","title":"Higgs boson + 0 jet"},{"location":"GitBook/find_the_higgs_2/#higgs-boson-1-jet","text":"Select: Number of Jets = 1 no b-tagged jets electron-muon channel only Reconstructed Dilepton Mass < 70 GeV Total Lepton Transverse Momentum > 30 GeV Opening angle between leptons < 80 The dominant background after all these cuts in the Higgs boson + 1 jet channel comes from $$WW$$ and top pair production. 2 Higgs events are identified, yielding a significance of 0.517.","title":"Higgs boson + 1 jet"},{"location":"GitBook/find_the_higgs_2/#have-a-go-yourself","text":"Perhaps try the $$H\\rightarrow W^+W^-$$ + 0 jet, but separate it into leptonic channels and tune the cuts to maximise the number of $$H\\rightarrow W^+W^-$$ events with maximum significance. Or try something completely different...","title":"Have a go yourself!"},{"location":"GitBook/histogram-analyser-2/","text":"Higgs to WW - simulated + real data The second Histogram Analyser includes data. This is shown by the black dots, with error bars. Here we will just be looking at the electron-muon channel. Before, we had 17 Higgs candidates (see Events per Channel histogram below), now we are looking at just 8 Higgs candidates (see Number of Expected Events histogram above). However, the $$Z$$ background is much reduced, so that makes it a good choice. The numbers shown in Number of Expected Events is calculated by the simulated Monte Carlo, as before. We have also added a new histogram, transverse mass. Transverse mass is analogous to invariant mass, but neglects the longitudinal momenta of the decay products. Transverse mass, $$m_T$$, is a useful quantity to define for use in particle physics as it is invariant under Lorentz boost along the z direction. In natural units it is: $$m_T^2 = m^2 + p_x^2 + p_y^2 = E^2 - p_z^2$$ where the z-direction is along the beam pipe and so $$p_x$$ and $$p_y$$ are the momentum perpendicular to the beam pipe and $$m$$ is the invariant mass. In this study, transverse mass is defined as $$m_T = ((E_T^{ll} + E_T^{miss})^2 - | p_T^{ll} + E_T^{miss} |^2 ) ^{1/2} $$ where $$ E_T^{ll} = (|p_T^{ll}|^2 + m_{ll}^2 )^{1/2} $$ If you select just the Higgs events by clicking on the $$H \\rightarrow WW$$ in 'Expected Number of Events' histogram, you will see the transverse mass of the Higgs. As expected, it peaks at the mass of the Higgs, 125 GeV. Select events with 2 jets by using your cursor to select N(Jets)=2. You will notice that both the data points and the simulated Monte Carlo distributions change. The data and simulated Monte Carlo are not exactly the same, but the general agreement is very good. This shows that these processes are well understood and well modelled. As before, make some selections to separate the Higgs boson signal from the background. Can you increase the significance to over 0.2 ? Below is an event display, where a Higgs candidate has been identified decaying into an electron and muon.","title":"Higgs to WW - simulated + real data"},{"location":"GitBook/histogram-analyser-2/#higgs-to-ww-simulated-real-data","text":"The second Histogram Analyser includes data. This is shown by the black dots, with error bars. Here we will just be looking at the electron-muon channel. Before, we had 17 Higgs candidates (see Events per Channel histogram below), now we are looking at just 8 Higgs candidates (see Number of Expected Events histogram above). However, the $$Z$$ background is much reduced, so that makes it a good choice. The numbers shown in Number of Expected Events is calculated by the simulated Monte Carlo, as before. We have also added a new histogram, transverse mass. Transverse mass is analogous to invariant mass, but neglects the longitudinal momenta of the decay products. Transverse mass, $$m_T$$, is a useful quantity to define for use in particle physics as it is invariant under Lorentz boost along the z direction. In natural units it is: $$m_T^2 = m^2 + p_x^2 + p_y^2 = E^2 - p_z^2$$ where the z-direction is along the beam pipe and so $$p_x$$ and $$p_y$$ are the momentum perpendicular to the beam pipe and $$m$$ is the invariant mass. In this study, transverse mass is defined as $$m_T = ((E_T^{ll} + E_T^{miss})^2 - | p_T^{ll} + E_T^{miss} |^2 ) ^{1/2} $$ where $$ E_T^{ll} = (|p_T^{ll}|^2 + m_{ll}^2 )^{1/2} $$ If you select just the Higgs events by clicking on the $$H \\rightarrow WW$$ in 'Expected Number of Events' histogram, you will see the transverse mass of the Higgs. As expected, it peaks at the mass of the Higgs, 125 GeV. Select events with 2 jets by using your cursor to select N(Jets)=2. You will notice that both the data points and the simulated Monte Carlo distributions change. The data and simulated Monte Carlo are not exactly the same, but the general agreement is very good. This shows that these processes are well understood and well modelled. As before, make some selections to separate the Higgs boson signal from the background. Can you increase the significance to over 0.2 ? Below is an event display, where a Higgs candidate has been identified decaying into an electron and muon.","title":"Higgs to WW - simulated + real data"},{"location":"GitBook/international-masterclass/","text":"International Masterclass If you are not an expert in particle physics or ATLAS jargon you might want to have a look at the International Masterclass .","title":"International Masterclass"},{"location":"GitBook/international-masterclass/#international-masterclass","text":"If you are not an expert in particle physics or ATLAS jargon you might want to have a look at the International Masterclass .","title":"International Masterclass"},{"location":"GitBook/particle-physics-masterclasses/","text":"International Masterclasses Take a look at the International Masterclasses.","title":"International Masterclasses"},{"location":"GitBook/particle-physics-masterclasses/#international-masterclasses","text":"Take a look at the International Masterclasses.","title":"International Masterclasses"},{"location":"GitBook/root_browser_final_plots/","text":"ROOTbrowser final plots Complex High Energy Physics (HEP) plots in action. ROOTbrowser also allows you to take a look at some prepared HEP histograms. An analysis has been implemented for single $$W$$ boson events where the $$W$$ boson decays to leptons. The drop-down menu (second text box) contains a number of examples of final plots from this $$W$$ analysis. As before, select the file you are interested in In this case 'examples_final_ploys/WtMass.root Press 'Load' button Then display the histogram. In this case, click on 'WtMass;1' Data is displayed with black filled dots. The various simulated samples are shown in filled colours, stacked ontop of each other. The overall shape of the combined simulated samples is very similar to the data distribution. There is fairly good agreement between data and simulated data. The $$W$$ analysis is potentially prone to QCD contributions as there is only one lepton present which may come from non-prompt sources mimicking the desired final state. Therefore, potential disagreements must always be understood as a sign that the QCD contributions are not taken into account. QCD samples were not included as these have very low statistics after a selection while having a large file size. The distributions of the transverse mass as well as the missing transverse momentum are affected by the omission of QCD contributions, which predominantly populate the low missing transverse momentum and low transverse mass regions. The magnetic field bends the charged particles thus allowing measurement of the momentum by using the curvature of the tracks. The histogram shows the momentum of the lepton transverse to the beam. If you hover your cursor over a data point, statistics boxes will be shown. The bottom box shows the information for data, so in this case there are 858 leptons with $$p_T$$ between 50 and 60 GeV. The top statistics box shows the total simulated data contribution, 961.4 entries. Lepton energy is measured by the electromagnetic calorimeters. The overall description of the lepton kinematics by the simulated data is good. Less well described are the tracking and isolation variables. This suggests that QCD contributions are missing. In this region QCD processes would contribute by either the misidentification of a jet as a lepton or by a hadron decay to leptons inside a jet. These so-called non-prompt leptons are not well isolated resulting in higher values for the isolation variables. Jet MV1 displays the b-tagging weight obtained from a jet tagging algorithm based on Multi-Variate techniques. High values indicate jets originating from $$b$$-quarks (b-tagged jets). The jet variables are reasonably well described by the simulated data. The slight disagreement may be attributed to missing QCD contributions. Example final plots available WtMass : Transverse Mass of the $$W$$ boson candidate etmiss : Missing transverse momentum jet_MV1 : Weight from algorithm based on Multi-Variate techniques jet_eta : Jet pseudorapidity jet_jvf : Jet Vertex Fraction (JVF) jet_m : Jet mass jet_pt : Jet momentum lep_E : Lepton energy lep_charge : Lepton charge lep_d0 : The signed transverse impact track parameter lep_eta : Lepton pseudorapidity lep_etconerel20 : Scalar sum of ET of tracks in a cone of R=0.2 around lepton, not including lepton ET itself lep_n : Number of leptons lep_phi : Lepton phi lep_pt : Lepton transverse momentum lep_ptconerel30 : Scalar sum of $$p_T$$ of tracks in a cone of R=0.3 around lepton, not including lepton $$p_T$$ itself lep_type : Number signifying the lepton type (electron, muon, tau) lep_z0 : Z-coordinate of the track associated to the lepton wrt the primary vertex n_jets : Number of jets pvxp_n : Number of primary vertices vxp_z : Z-position of the primary vertex","title":"ROOTbrowser final plots"},{"location":"GitBook/root_browser_final_plots/#rootbrowser-final-plots","text":"","title":"ROOTbrowser final plots"},{"location":"GitBook/root_browser_final_plots/#complex-high-energy-physics-hep-plots-in-action","text":"ROOTbrowser also allows you to take a look at some prepared HEP histograms. An analysis has been implemented for single $$W$$ boson events where the $$W$$ boson decays to leptons. The drop-down menu (second text box) contains a number of examples of final plots from this $$W$$ analysis. As before, select the file you are interested in In this case 'examples_final_ploys/WtMass.root Press 'Load' button Then display the histogram. In this case, click on 'WtMass;1' Data is displayed with black filled dots. The various simulated samples are shown in filled colours, stacked ontop of each other. The overall shape of the combined simulated samples is very similar to the data distribution. There is fairly good agreement between data and simulated data. The $$W$$ analysis is potentially prone to QCD contributions as there is only one lepton present which may come from non-prompt sources mimicking the desired final state. Therefore, potential disagreements must always be understood as a sign that the QCD contributions are not taken into account. QCD samples were not included as these have very low statistics after a selection while having a large file size. The distributions of the transverse mass as well as the missing transverse momentum are affected by the omission of QCD contributions, which predominantly populate the low missing transverse momentum and low transverse mass regions. The magnetic field bends the charged particles thus allowing measurement of the momentum by using the curvature of the tracks. The histogram shows the momentum of the lepton transverse to the beam. If you hover your cursor over a data point, statistics boxes will be shown. The bottom box shows the information for data, so in this case there are 858 leptons with $$p_T$$ between 50 and 60 GeV. The top statistics box shows the total simulated data contribution, 961.4 entries. Lepton energy is measured by the electromagnetic calorimeters. The overall description of the lepton kinematics by the simulated data is good. Less well described are the tracking and isolation variables. This suggests that QCD contributions are missing. In this region QCD processes would contribute by either the misidentification of a jet as a lepton or by a hadron decay to leptons inside a jet. These so-called non-prompt leptons are not well isolated resulting in higher values for the isolation variables. Jet MV1 displays the b-tagging weight obtained from a jet tagging algorithm based on Multi-Variate techniques. High values indicate jets originating from $$b$$-quarks (b-tagged jets). The jet variables are reasonably well described by the simulated data. The slight disagreement may be attributed to missing QCD contributions.","title":"Complex High Energy Physics (HEP) plots in action."},{"location":"GitBook/root_browser_final_plots/#example-final-plots-available","text":"WtMass : Transverse Mass of the $$W$$ boson candidate etmiss : Missing transverse momentum jet_MV1 : Weight from algorithm based on Multi-Variate techniques jet_eta : Jet pseudorapidity jet_jvf : Jet Vertex Fraction (JVF) jet_m : Jet mass jet_pt : Jet momentum lep_E : Lepton energy lep_charge : Lepton charge lep_d0 : The signed transverse impact track parameter lep_eta : Lepton pseudorapidity lep_etconerel20 : Scalar sum of ET of tracks in a cone of R=0.2 around lepton, not including lepton ET itself lep_n : Number of leptons lep_phi : Lepton phi lep_pt : Lepton transverse momentum lep_ptconerel30 : Scalar sum of $$p_T$$ of tracks in a cone of R=0.3 around lepton, not including lepton $$p_T$$ itself lep_type : Number signifying the lepton type (electron, muon, tau) lep_z0 : Z-coordinate of the track associated to the lepton wrt the primary vertex n_jets : Number of jets pvxp_n : Number of primary vertices vxp_z : Z-position of the primary vertex","title":"Example final plots available"},{"location":"GitBook/rootbrowser/","text":"Analysis Browser ROOTbrowser is a web based tool for displaying and analysing data and Monte-Carlo simulated data. Select a dataset using the drop-down menu (second text box). The name of the dataset now appears in the top text box. Press the \"Load\" button. The available variables are then displayed. Select the variable to view the distribution. One or more datasets can be loaded. One or more variables can be displayed at a time. Several display options are available (grid option circled in red below). 'Simple' option just displays one histogram. 'grid' option displays many histograms from two ('grid 1x2' option) up to sixteen ('grid 4x4'option). If you want to change option after you have selected your file just hit 'Reset' and your histograms are erased, but your file selection remains. Further display criteria (circled in green below) such as setting the x-axis and/or y-axis to logarithmic scale are available.","title":"Analysis Browser"},{"location":"GitBook/rootbrowser/#analysis-browser","text":"ROOTbrowser is a web based tool for displaying and analysing data and Monte-Carlo simulated data. Select a dataset using the drop-down menu (second text box). The name of the dataset now appears in the top text box. Press the \"Load\" button. The available variables are then displayed. Select the variable to view the distribution. One or more datasets can be loaded. One or more variables can be displayed at a time. Several display options are available (grid option circled in red below). 'Simple' option just displays one histogram. 'grid' option displays many histograms from two ('grid 1x2' option) up to sixteen ('grid 4x4'option). If you want to change option after you have selected your file just hit 'Reset' and your histograms are erased, but your file selection remains. Further display criteria (circled in green below) such as setting the x-axis and/or y-axis to logarithmic scale are available.","title":"Analysis Browser"},{"location":"GitBook/rootbrowser_datasets/","text":"ROOTbrowser datasets There are two real data datasets for you to look at * data_Egamma.root : electrons and photons * data_Muons.root : muons Then there are a range of simulated data datasets from * ggH125_ZZ4lep.root : Higgs production via gluon fusion * VBFH125_ZZ4lep.root : Vector Boson Fusion Higgs Production * WW.root : $$W$$ boson pair * WZ.root : $$WZ$$ boson pair * Zee.root : $$Z$$ boson decay to two electrons * Zmumu.root : $$Z$$ boson decay to two muons * Ztautau.root : $$Z$$ decay to two taus * ZZ.root : $$Z$$ boson pair Simulated data Simulated events are a key feature for the LHC experiments, commonly named Monte Carlo or more precisely Monte Carlo simulated data. These events are simulated using current theoretical models and are used to compare theory with real collision data. The full simulation requires the following steps * Event generation: Proton-proton collisions are simulated using programs relying on theoretical calculations, phenomenological models and experimental inputs. Detector Simulation: Interaction of the generated particles inside the ATLAS detector is simulated. Digitisation: The detector response is simulated and written in a format compatible with the real output of the detector. Digitised signals from several simulated events are added to simulate the pile-up conditions caused by the high rate of collisions in the LHC. Reconstruction: Particle trajectories and energies are calculated from the detector output. Such final samples are used by the physicists. Comparing data and simulated data Data and simulated data do not always agree. This can be due to various reasons, such as * conditions not being exactly the same e.g. energy, pile-up etc., * not all background processes are included in the simulated data, or * the physics has not been exactly modelled by the theory. If the data and simulated data does not agree, it is important that physicists understand why.","title":"ROOTbrowser datasets"},{"location":"GitBook/rootbrowser_datasets/#rootbrowser-datasets","text":"There are two real data datasets for you to look at * data_Egamma.root : electrons and photons * data_Muons.root : muons Then there are a range of simulated data datasets from * ggH125_ZZ4lep.root : Higgs production via gluon fusion * VBFH125_ZZ4lep.root : Vector Boson Fusion Higgs Production * WW.root : $$W$$ boson pair * WZ.root : $$WZ$$ boson pair * Zee.root : $$Z$$ boson decay to two electrons * Zmumu.root : $$Z$$ boson decay to two muons * Ztautau.root : $$Z$$ decay to two taus * ZZ.root : $$Z$$ boson pair","title":"ROOTbrowser datasets"},{"location":"GitBook/rootbrowser_datasets/#simulated-data","text":"Simulated events are a key feature for the LHC experiments, commonly named Monte Carlo or more precisely Monte Carlo simulated data. These events are simulated using current theoretical models and are used to compare theory with real collision data. The full simulation requires the following steps * Event generation: Proton-proton collisions are simulated using programs relying on theoretical calculations, phenomenological models and experimental inputs. Detector Simulation: Interaction of the generated particles inside the ATLAS detector is simulated. Digitisation: The detector response is simulated and written in a format compatible with the real output of the detector. Digitised signals from several simulated events are added to simulate the pile-up conditions caused by the high rate of collisions in the LHC. Reconstruction: Particle trajectories and energies are calculated from the detector output. Such final samples are used by the physicists.","title":"Simulated data"},{"location":"GitBook/rootbrowser_datasets/#comparing-data-and-simulated-data","text":"Data and simulated data do not always agree. This can be due to various reasons, such as * conditions not being exactly the same e.g. energy, pile-up etc., * not all background processes are included in the simulated data, or * the physics has not been exactly modelled by the theory. If the data and simulated data does not agree, it is important that physicists understand why.","title":"Comparing data and simulated data"},{"location":"GitBook/separate_signals/","text":"Separate Signals Let's look at the simulated data. Using the Histogram Analyser we can look at each sample separately and understand a little more about their characteristics. This will help us separate our signal from the background later. Select the sample by clicking on the bar in the Expected Number of Events histogram. The rest of the histograms now just display the characteristics of your chosen sample. $$H\\rightarrow W^+W^-$$ $$H\\rightarrow W^+W^- \\rightarrow \\ell^+\\ell^-\\nu \\bar\\nu$$ ( $$\\ell$$ = electron, muon) Our signal is the Higgs boson which decays into two $$W$$ bosons which subsequently decay into leptons and neutrinos. Let's look at the individual histograms: The analysis considers electron and muon decays of the Higgs boson, so the events occur in all three channels. The reconstructed mass from the two leptons peaks at 25-45 GeV. The majority of Higgs events contain 0 or 1 jet. Most events have no b-tagged jets. The total lepton transverse momentum peaks around 60 GeV. Missing transverse momentum is due to the neutrinos in the final state. The opening angle between the missing transverse momentum and the leptons tends to be large. The opening angle of the leptons from Higgs decays tends to be small. $$WW$$ Two $$W$$ bosons both decaying leptonically. Let's look at the individual histograms: The analysis considers electron and muon decays of the $$W$$ bosons, so the events occur in all three channels. The reconstructed mass from the two leptons peaks at around 80 GeV. The majority of $$WW$$ events contain 0 or 1 jet. Most events have no b-tagged jets. The total lepton transverse momentum peaks around 20-40 GeV. Missing transverse momentum is due to the neutrinos in the final state. The opening angle between the missing transverse momentum and the leptons tends to be large. The opening angle of the leptons from Higgs decays tends to be large. Note this is different to the distribution for Higgs events. Overall, the distributions are not so different from those for $$H\\rightarrow W^+W^-$$, hence it is a difficult background process to remove. Displaying both samples together shows why it is difficult to separate the $$H\\rightarrow W^+W^-$$ signal from the $$WW$$ background. top quark pair production ($$t \\bar t$$) The top quark is the heaviest subatomic particle ever observed, with a mass that is about as heavy as an entire atom of gold. Top quarks are also among the most fleeting of particles, with a lifetime of about a trillionth of a trillionth of a second. Due to its high mass and short lifetime, the top quark provides a unique environment to study a bare quark. Looking at the individual histograms: The events occur in all three channels. The reconstructed mass from the two leptons peaks at around 80 GeV. The majority of $$t\\bar t$$ events contain at least 2 jets. Most events have b-tagged jets. The total lepton transverse momentum peaks around 60-70 GeV. Missing transverse momentum is larger than seen in $$H\\rightarrow W^+W^-$$ and $$WW$$ events. The opening angle between the missing transverse momentum and the leptons is fairly evenly distributed over the whole $$\\phi$$ range. The opening angle of the leptons from top quark production is fairly evenly distributed over the whole $$\\phi$$ range, tending to slightly larger values. Therefore demanding non b-tagged jets, only 0 or 1 jet, small opening angle between leptons and small opening angle between MET and leptons will reduce the top quark contribution. $$Z$$ Looking at the individual histograms: The events occur in the di-electron and di-muon channels. The reconstructed mass from the two leptons peaks at around 90 GeV. The majority of events do not contain jets. Most events do not have b-tagged jets. The total lepton transverse momentum peaks around zero. The opening angle between the missing transverse momentum and the leptons is fairly evenly distributed over the whole $$\\phi$$ range, tending to slightly larger values. The opening angle of the leptons tends to be large (back-to-back) The $$Z$$ boson has a mass of 91 GeV, which is reconstructed from the mass of the two leptons. Requiring Reconstructed Dilepton Mass to be less than 75 GeV removes over 90 % of the Z events. This is an important cut to remove this background from our Higgs boson signal.","title":"Separate Signals"},{"location":"GitBook/separate_signals/#separate-signals","text":"Let's look at the simulated data. Using the Histogram Analyser we can look at each sample separately and understand a little more about their characteristics. This will help us separate our signal from the background later. Select the sample by clicking on the bar in the Expected Number of Events histogram. The rest of the histograms now just display the characteristics of your chosen sample.","title":"Separate Signals"},{"location":"GitBook/separate_signals/#hrightarrow-ww-","text":"$$H\\rightarrow W^+W^- \\rightarrow \\ell^+\\ell^-\\nu \\bar\\nu$$ ( $$\\ell$$ = electron, muon) Our signal is the Higgs boson which decays into two $$W$$ bosons which subsequently decay into leptons and neutrinos. Let's look at the individual histograms: The analysis considers electron and muon decays of the Higgs boson, so the events occur in all three channels. The reconstructed mass from the two leptons peaks at 25-45 GeV. The majority of Higgs events contain 0 or 1 jet. Most events have no b-tagged jets. The total lepton transverse momentum peaks around 60 GeV. Missing transverse momentum is due to the neutrinos in the final state. The opening angle between the missing transverse momentum and the leptons tends to be large. The opening angle of the leptons from Higgs decays tends to be small.","title":"$$H\\rightarrow W^+W^-$$"},{"location":"GitBook/separate_signals/#ww","text":"Two $$W$$ bosons both decaying leptonically. Let's look at the individual histograms: The analysis considers electron and muon decays of the $$W$$ bosons, so the events occur in all three channels. The reconstructed mass from the two leptons peaks at around 80 GeV. The majority of $$WW$$ events contain 0 or 1 jet. Most events have no b-tagged jets. The total lepton transverse momentum peaks around 20-40 GeV. Missing transverse momentum is due to the neutrinos in the final state. The opening angle between the missing transverse momentum and the leptons tends to be large. The opening angle of the leptons from Higgs decays tends to be large. Note this is different to the distribution for Higgs events. Overall, the distributions are not so different from those for $$H\\rightarrow W^+W^-$$, hence it is a difficult background process to remove. Displaying both samples together shows why it is difficult to separate the $$H\\rightarrow W^+W^-$$ signal from the $$WW$$ background.","title":"$$WW$$"},{"location":"GitBook/separate_signals/#top-quark-pair-production-40t-bar-t41","text":"The top quark is the heaviest subatomic particle ever observed, with a mass that is about as heavy as an entire atom of gold. Top quarks are also among the most fleeting of particles, with a lifetime of about a trillionth of a trillionth of a second. Due to its high mass and short lifetime, the top quark provides a unique environment to study a bare quark. Looking at the individual histograms: The events occur in all three channels. The reconstructed mass from the two leptons peaks at around 80 GeV. The majority of $$t\\bar t$$ events contain at least 2 jets. Most events have b-tagged jets. The total lepton transverse momentum peaks around 60-70 GeV. Missing transverse momentum is larger than seen in $$H\\rightarrow W^+W^-$$ and $$WW$$ events. The opening angle between the missing transverse momentum and the leptons is fairly evenly distributed over the whole $$\\phi$$ range. The opening angle of the leptons from top quark production is fairly evenly distributed over the whole $$\\phi$$ range, tending to slightly larger values. Therefore demanding non b-tagged jets, only 0 or 1 jet, small opening angle between leptons and small opening angle between MET and leptons will reduce the top quark contribution.","title":"top quark pair production ($$t \\bar t$$)"},{"location":"GitBook/separate_signals/#z","text":"Looking at the individual histograms: The events occur in the di-electron and di-muon channels. The reconstructed mass from the two leptons peaks at around 90 GeV. The majority of events do not contain jets. Most events do not have b-tagged jets. The total lepton transverse momentum peaks around zero. The opening angle between the missing transverse momentum and the leptons is fairly evenly distributed over the whole $$\\phi$$ range, tending to slightly larger values. The opening angle of the leptons tends to be large (back-to-back) The $$Z$$ boson has a mass of 91 GeV, which is reconstructed from the mass of the two leptons. Requiring Reconstructed Dilepton Mass to be less than 75 GeV removes over 90 % of the Z events. This is an important cut to remove this background from our Higgs boson signal.","title":"$$Z$$"},{"location":"GitBook/the-higgs-boson/","text":"The Higgs Boson The Standard Model of particle physics is a theory that describes the known matter in terms of its elementary constituents and their interactions. It is a widely proven and very successful theory in modern physics. The Higgs boson is a fundamental particle, first observed by ATLAS and CMS in 2012, although theorised in the 1960s. The Higgs boson is the carrier particle for the Higgs field, a field present throughout our universe, which gives particles their mass. The more a particle interacts with the Higgs field, the higher its mass. Higgs boson production Standard Model production of the Higgs boson at the LHC is dominated by the gluon fusion process: $$gg \\rightarrow H$$ followed by the vector-boson fusion process: $$qq' \\rightarrow qq'H$$ Associated production also have sizeable contributions, with a $$W$$ boson : a $$Z$$ boson : or a pair of top quarks: $$q\\bar q/gg \\rightarrow t\\bar t H$$ Smaller contributions are expected from production in association with $$b$$-quarks : $$b\\bar bH$$ a single top quark : $$tH$$ The figure above shows the Standard Model Higgs boson production cross sections as a function of the center of mass energy, $$\\sqrt{s}$$, \ufffcfor pp collisions. Effectively, how likely each type of Higgs production is, for different LHC energies. The theoretical uncertainties are indicated as a band PDG . Quantum chromodynamics (QCD) and Electroweak (EW) models are used to predict the production cross sections. Next-to-leading order(NLO) and next-to-next-to leading order (NNLO) calculations are carried. High order corrections are required to achieve the desired precision for these predictions. Higgs decay According to the Standard Model, the Higgs boson can decay into pairs of fermions or bosons. The Higgs boson mass is not predicted by the Standard Model, but once measured the production cross sections and branching ratios can be precisely calculated. The Standard Model Higgs boson decay branching ratios and total width are shown in the figure above [ PDG ]. You can see that the decay modes change in prominance depending on the mass of the Higgs, M$$_{H}$$. Effectively, this diagram expresses how likely the Higgs is to decay into a certain particle, or group of particles, depending on the mass of the Higgs. The Higgs mass has now been measured to be 125 GeV ( see combined measurement by ATLAS and CMS ). We can see from the figure above that the prominent decay modes at M$$_{H}$$= 125 GeV are $$ H \\rightarrow b\\bar b$$ $$ H \\rightarrow WW$$ followed by $$ H \\rightarrow gg$$ $$ H \\rightarrow \\tau^{+}\\tau{-}$$ $$ H \\rightarrow c\\bar c$$ $$ H \\rightarrow ZZ $$ The following table displays the branching ratios and the relative uncertainty for a Standard Model Higgs boson with mass M$$_{H}$$ = 125 GeV PDG . The decay mode with the highest branching ratio (BR) is the decay to hadrons , BR $$\\sim$$ 70%, which is not easy to detect due to QCD background. A large fraction of the leptonic decays are to a pair of neutrinos , BR $$\\sim$$ 20%, which are difficult to detect since they hardly interact with matter. The decay to pairs of electrons, muons and taus have a BR of about 10% of the total. In fact, the tau life time is very short, 3x10$$^{-13}$$s, so it can be reconstructed only from its decay products. The efficiency of reconstructing taus is much lower than that of electrons and muons. So essentially, focusing on decays into electrons and muons, we are chasing just 6% of all the possible Higgs produced in the LHC .","title":"The Higgs Boson"},{"location":"GitBook/the-higgs-boson/#the-higgs-boson","text":"The Standard Model of particle physics is a theory that describes the known matter in terms of its elementary constituents and their interactions. It is a widely proven and very successful theory in modern physics. The Higgs boson is a fundamental particle, first observed by ATLAS and CMS in 2012, although theorised in the 1960s. The Higgs boson is the carrier particle for the Higgs field, a field present throughout our universe, which gives particles their mass. The more a particle interacts with the Higgs field, the higher its mass.","title":"The Higgs Boson"},{"location":"GitBook/the-higgs-boson/#higgs-boson-production","text":"Standard Model production of the Higgs boson at the LHC is dominated by the gluon fusion process: $$gg \\rightarrow H$$ followed by the vector-boson fusion process: $$qq' \\rightarrow qq'H$$ Associated production also have sizeable contributions, with a $$W$$ boson : a $$Z$$ boson : or a pair of top quarks: $$q\\bar q/gg \\rightarrow t\\bar t H$$ Smaller contributions are expected from production in association with $$b$$-quarks : $$b\\bar bH$$ a single top quark : $$tH$$ The figure above shows the Standard Model Higgs boson production cross sections as a function of the center of mass energy, $$\\sqrt{s}$$, \ufffcfor pp collisions. Effectively, how likely each type of Higgs production is, for different LHC energies. The theoretical uncertainties are indicated as a band PDG . Quantum chromodynamics (QCD) and Electroweak (EW) models are used to predict the production cross sections. Next-to-leading order(NLO) and next-to-next-to leading order (NNLO) calculations are carried. High order corrections are required to achieve the desired precision for these predictions.","title":"Higgs boson production"},{"location":"GitBook/the-higgs-boson/#higgs-decay","text":"According to the Standard Model, the Higgs boson can decay into pairs of fermions or bosons. The Higgs boson mass is not predicted by the Standard Model, but once measured the production cross sections and branching ratios can be precisely calculated. The Standard Model Higgs boson decay branching ratios and total width are shown in the figure above [ PDG ]. You can see that the decay modes change in prominance depending on the mass of the Higgs, M$$_{H}$$. Effectively, this diagram expresses how likely the Higgs is to decay into a certain particle, or group of particles, depending on the mass of the Higgs. The Higgs mass has now been measured to be 125 GeV ( see combined measurement by ATLAS and CMS ). We can see from the figure above that the prominent decay modes at M$$_{H}$$= 125 GeV are $$ H \\rightarrow b\\bar b$$ $$ H \\rightarrow WW$$ followed by $$ H \\rightarrow gg$$ $$ H \\rightarrow \\tau^{+}\\tau{-}$$ $$ H \\rightarrow c\\bar c$$ $$ H \\rightarrow ZZ $$ The following table displays the branching ratios and the relative uncertainty for a Standard Model Higgs boson with mass M$$_{H}$$ = 125 GeV PDG . The decay mode with the highest branching ratio (BR) is the decay to hadrons , BR $$\\sim$$ 70%, which is not easy to detect due to QCD background. A large fraction of the leptonic decays are to a pair of neutrinos , BR $$\\sim$$ 20%, which are difficult to detect since they hardly interact with matter. The decay to pairs of electrons, muons and taus have a BR of about 10% of the total. In fact, the tau life time is very short, 3x10$$^{-13}$$s, so it can be reconstructed only from its decay products. The efficiency of reconstructing taus is much lower than that of electrons and muons. So essentially, focusing on decays into electrons and muons, we are chasing just 6% of all the possible Higgs produced in the LHC .","title":"Higgs decay"},{"location":"GitBook/the_display_histograms/","text":"Histogram Analyser Physicists use cuts to select events of interest. Cuts preferentially remove the unwanted processes (background) but leave as much as possible of the desired process (signal). It is useful to have a good understanding of the physics processes involved when applying cuts. We have created two Histogram Analysers, to help visualise the data: The first Histogram Analyser displays just simulated events. The second Histogram Analyser displays both real data and simulated events. Both histogram analysers display four physics processes. The four processes are $$H\\rightarrow W^+W^-$$, $$WW$$, $$t\\bar t$$ and $$Z$$. These processes are discussed in the next chapter. Each process is represented by a different colour in Histogram Analyser. Make cuts using your cursor. Use the cursor to select a specific range in one of the histograms. The selected ranges will be coloured, whilst non-selected ranges will be greyed out. When you make cuts on a variable the relative contributions of the four processes will change. To clear your selection on a specific histogram click on the white background within the histogram area. To clear all your selections click on \"Histogram Analyser\" under Get Started in the main top menu. The histograms explained Higgs to WW - simulated data Histogram Analyser displays nine histograms. The description of each follows. Expected Number of Events for 1/fb This histogram shows the number of events expected to be detected, reconstructed and recorded by ATLAS for 1 inverse femtobarn (1/fb) of data. One inverse femtobarn corresponds to approximately 100 trillion proton-proton collisions. The expected number of events reconstructed and recorded by ATLAS is different to the number of events produced. Some events will not be reconstructed due to the way the detector is constructed, the resolution of the sub-detectors, reconstruction efficiency and other inefficiencies. With no cuts, we have seventeen $$H\\rightarrow W^+W^-$$ events, with a total background of 613349 events. The majority of the background is $$Z$$ boson production. The significance of the $$H\\rightarrow W^+W^-$$ events quantifies how \"significant\" the Higgs sample is with respect to the background. It is calculated by $$(\\text{Number of } H\\rightarrow W^+W^- \\text{events}) / \\sqrt{\\text{Number of background events}}$$). The larger the significance value is, the better job you have done extracting the Higgs signal . Channel The leptonic decay channels are shown here: dielectron (ee), dimuon (mm) and electron-muon (em). Decays to taus or hadrons are not considered in Histogram Analyser. Histogram Analyser showing just simulated data, displays three leptonic channels. Histogram Analyser showing simulated and real data, displays just the electron-muon channel, so this histogram is not displayed. Reconstructed Dilepton Mass [GeV] This histogram displays the mass reconstructed from the two leptons in the final state. With no cuts, this peaks at 90 GeV, due the huge $$Z$$ boson contribution. We can remove a large number of $$Z$$ boson events by selecting Reconstructed Dilepton Mass to be less than 75 GeV, whilst hardly touching our Higgs signal. The $$H\\rightarrow W^+W^-$$ sample significance increases from 0.021 to 0.110 with this cut. It is thus a useful quantity to use to reduce the huge $$Z$$ boson background. Number of Jets Number of jets found in the event. When selecting two or more jets we see that the $$Z$$ boson contribution decreases (from 611276 to 25422) and the $$t\\bar{t}$$ contribution becomes more important. Selecting two or more jets, the ratio of ttbar to $$Z$$ events increases from 1334/611276 = 0.002 to 1038/25422 = 0.04 and the green ttbar contribution is now noticeable in the histograms. Top-quark pair production leads to $$WW$$+jets final states. Are Jets b-tagged? Jets originating from $$b$$-quarks are identified and labelled, or tagged , using so-called b-tagging algorithms. $$b$$-tagged jets are expected in top quark decays, but not in leptonic $$W$$ or $$Z$$ boson decays. Selecting 'Are Jets b-tagged' as yes, the ratio of ttbar to $$Z$$ events increases from 1334/611276 = 0.002 to 1041/7227 = 0.14 and the green ttbar contribution is now noticeable in the histograms. Missing Transverse Momentum (MET) [GeV] In the LHC, the initial energy of the colliding partons (quarks or gluons) along the beam axis is not known. This is due to the energy of each proton being shared and constantly exchanged between its constituents. However, the initial momentum of particles travelling transverse to the beam axis is zero. Therefore, any net momentum in the transverse direction indicates missing transverse momentum. Missing transverse momentum is used to infer the presence of non-detectable particles such as the neutrino. It is also expected to be a signature of many predicted physics events beyond the Standard Model, for example the lightest supersymmetric particle. The standard abbreviation for missing transverse momentum is MET, for historical reasons. $$Z$$ boson decays to charged leptons do not have any neutrinos in the final state while the other processes do. That is why requiring missing transverse momentum removes $$Z$$ boson events. Select missing transverse momentum and watch how the ratio of $$WW$$ and ttbar to $$Z$$ events changes. Total Lepton Transverse Momentum [GeV] This is the vectorial sum of the transverse momenta of the observed charged leptons. For $$Z$$ boson events, total lepton transverse momentum peaks at zero since the transverse momenta of both leptons cancel each other. For the other processes this cancellation is not as pronounced. Their distributions peak at between 30 and 80 GeV. Opening Angle Between Leptons [phi] This is the opening angle, measured in phi (\ud835\udf19), between the two leptons. The azimuthal angle $$\\phi$$ is measured from the $$x$$-axis, around the beam. In the event display above, two lepton tracks are displayed in red and the opening angle between the two leptons is marked in blue. If the leptons are emitted back-to-back, this is displayed on the histogram as 180 degrees. $$H\\rightarrow W^+W^-$$events show a peak at low values in contrast to all other processes. Opening Angle Between MET and Leptons [phi] This is the opening angle, measured in phi (\ud835\udf19), between the missing transverse momentum (MET) and the two leptons. In the event display above, missing transverse energy is displayed by the dotted yellow line. The midline between the two lepton tracks (the direction of the vectorial sum of their transverse momenta) is represented by the dotted red line. The opening angle between the MET and leptons is shown in yellow. Events with $$t\\bar t$$ and $$Z$$ show a relatively flat distribution in this variable whereas $$H\\rightarrow W^+W^-$$ and $$WW$$ peak at large values. This is a useful discriminant to remove background events.","title":"Histogram Analyser"},{"location":"GitBook/the_display_histograms/#histogram-analyser","text":"Physicists use cuts to select events of interest. Cuts preferentially remove the unwanted processes (background) but leave as much as possible of the desired process (signal). It is useful to have a good understanding of the physics processes involved when applying cuts. We have created two Histogram Analysers, to help visualise the data: The first Histogram Analyser displays just simulated events. The second Histogram Analyser displays both real data and simulated events. Both histogram analysers display four physics processes. The four processes are $$H\\rightarrow W^+W^-$$, $$WW$$, $$t\\bar t$$ and $$Z$$. These processes are discussed in the next chapter. Each process is represented by a different colour in Histogram Analyser.","title":"Histogram Analyser"},{"location":"GitBook/the_display_histograms/#make-cuts-using-your-cursor","text":"Use the cursor to select a specific range in one of the histograms. The selected ranges will be coloured, whilst non-selected ranges will be greyed out. When you make cuts on a variable the relative contributions of the four processes will change. To clear your selection on a specific histogram click on the white background within the histogram area. To clear all your selections click on \"Histogram Analyser\" under Get Started in the main top menu.","title":"Make cuts using your cursor."},{"location":"GitBook/the_display_histograms/#the-histograms-explained","text":"Higgs to WW - simulated data Histogram Analyser displays nine histograms. The description of each follows.","title":"The histograms explained"},{"location":"GitBook/the_display_histograms/#expected-number-of-events-for-1fb","text":"This histogram shows the number of events expected to be detected, reconstructed and recorded by ATLAS for 1 inverse femtobarn (1/fb) of data. One inverse femtobarn corresponds to approximately 100 trillion proton-proton collisions. The expected number of events reconstructed and recorded by ATLAS is different to the number of events produced. Some events will not be reconstructed due to the way the detector is constructed, the resolution of the sub-detectors, reconstruction efficiency and other inefficiencies. With no cuts, we have seventeen $$H\\rightarrow W^+W^-$$ events, with a total background of 613349 events. The majority of the background is $$Z$$ boson production. The significance of the $$H\\rightarrow W^+W^-$$ events quantifies how \"significant\" the Higgs sample is with respect to the background. It is calculated by $$(\\text{Number of } H\\rightarrow W^+W^- \\text{events}) / \\sqrt{\\text{Number of background events}}$$). The larger the significance value is, the better job you have done extracting the Higgs signal .","title":"Expected Number of Events for 1/fb"},{"location":"GitBook/the_display_histograms/#channel","text":"The leptonic decay channels are shown here: dielectron (ee), dimuon (mm) and electron-muon (em). Decays to taus or hadrons are not considered in Histogram Analyser. Histogram Analyser showing just simulated data, displays three leptonic channels. Histogram Analyser showing simulated and real data, displays just the electron-muon channel, so this histogram is not displayed.","title":"Channel"},{"location":"GitBook/the_display_histograms/#reconstructed-dilepton-mass-91gev93","text":"This histogram displays the mass reconstructed from the two leptons in the final state. With no cuts, this peaks at 90 GeV, due the huge $$Z$$ boson contribution. We can remove a large number of $$Z$$ boson events by selecting Reconstructed Dilepton Mass to be less than 75 GeV, whilst hardly touching our Higgs signal. The $$H\\rightarrow W^+W^-$$ sample significance increases from 0.021 to 0.110 with this cut. It is thus a useful quantity to use to reduce the huge $$Z$$ boson background.","title":"Reconstructed Dilepton Mass [GeV]"},{"location":"GitBook/the_display_histograms/#number-of-jets","text":"Number of jets found in the event. When selecting two or more jets we see that the $$Z$$ boson contribution decreases (from 611276 to 25422) and the $$t\\bar{t}$$ contribution becomes more important. Selecting two or more jets, the ratio of ttbar to $$Z$$ events increases from 1334/611276 = 0.002 to 1038/25422 = 0.04 and the green ttbar contribution is now noticeable in the histograms. Top-quark pair production leads to $$WW$$+jets final states.","title":"Number of Jets"},{"location":"GitBook/the_display_histograms/#are-jets-b-tagged","text":"Jets originating from $$b$$-quarks are identified and labelled, or tagged , using so-called b-tagging algorithms. $$b$$-tagged jets are expected in top quark decays, but not in leptonic $$W$$ or $$Z$$ boson decays. Selecting 'Are Jets b-tagged' as yes, the ratio of ttbar to $$Z$$ events increases from 1334/611276 = 0.002 to 1041/7227 = 0.14 and the green ttbar contribution is now noticeable in the histograms.","title":"Are Jets b-tagged?"},{"location":"GitBook/the_display_histograms/#missing-transverse-momentum-40met41-91gev93","text":"In the LHC, the initial energy of the colliding partons (quarks or gluons) along the beam axis is not known. This is due to the energy of each proton being shared and constantly exchanged between its constituents. However, the initial momentum of particles travelling transverse to the beam axis is zero. Therefore, any net momentum in the transverse direction indicates missing transverse momentum. Missing transverse momentum is used to infer the presence of non-detectable particles such as the neutrino. It is also expected to be a signature of many predicted physics events beyond the Standard Model, for example the lightest supersymmetric particle. The standard abbreviation for missing transverse momentum is MET, for historical reasons. $$Z$$ boson decays to charged leptons do not have any neutrinos in the final state while the other processes do. That is why requiring missing transverse momentum removes $$Z$$ boson events. Select missing transverse momentum and watch how the ratio of $$WW$$ and ttbar to $$Z$$ events changes.","title":"Missing Transverse Momentum (MET) [GeV]"},{"location":"GitBook/the_display_histograms/#total-lepton-transverse-momentum-91gev93","text":"This is the vectorial sum of the transverse momenta of the observed charged leptons. For $$Z$$ boson events, total lepton transverse momentum peaks at zero since the transverse momenta of both leptons cancel each other. For the other processes this cancellation is not as pronounced. Their distributions peak at between 30 and 80 GeV.","title":"Total Lepton Transverse Momentum [GeV]"},{"location":"GitBook/the_display_histograms/#opening-angle-between-leptons-91phi93","text":"This is the opening angle, measured in phi (\ud835\udf19), between the two leptons. The azimuthal angle $$\\phi$$ is measured from the $$x$$-axis, around the beam. In the event display above, two lepton tracks are displayed in red and the opening angle between the two leptons is marked in blue. If the leptons are emitted back-to-back, this is displayed on the histogram as 180 degrees. $$H\\rightarrow W^+W^-$$events show a peak at low values in contrast to all other processes.","title":"Opening Angle Between Leptons [phi]"},{"location":"GitBook/the_display_histograms/#opening-angle-between-met-and-leptons-91phi93","text":"This is the opening angle, measured in phi (\ud835\udf19), between the missing transverse momentum (MET) and the two leptons. In the event display above, missing transverse energy is displayed by the dotted yellow line. The midline between the two lepton tracks (the direction of the vectorial sum of their transverse momenta) is represented by the dotted red line. The opening angle between the MET and leptons is shown in yellow. Events with $$t\\bar t$$ and $$Z$$ show a relatively flat distribution in this variable whereas $$H\\rightarrow W^+W^-$$ and $$WW$$ peak at large values. This is a useful discriminant to remove background events.","title":"Opening Angle Between MET and Leptons [phi]"},{"location":"GitBook/variable_names/","text":"Variable Names If you are using ROOTbrowser to look at the datasets, here are the definitions of the variables. When there are two leptons present in the final state they are ordered by transverse momentum with the \"leading lepton\" having the highest transverse momentum and the \u201ctrailing lepton\" having the next highest value. Take a look at ATLAS events chapter for discussion of primary vertex and Glossary chapter for explanation of ATLAS coordinate system. |branchname | description | |-|-|-| |pvxp_n | number of primary vertices | |leadlep_E | energy of the leading lepton | |traillep_pt | transverse momentum of the trailing lepton | |vxp_z | z-position of the primary vertex (see ATLAS coordinate system)| |leadlep_type | number signifying the leading lepton type (e, mu, tau) of the lepton | |jet_pt | transverse momentum of the jet | |etmiss | Transverse energy of the missing momentum vector | |leadlep_ptcone30 | scalar sum of tracks $$p_T$$ in a cone of R=0.3 around leading lepton, not including lepton $$p_T$$ itself | |traillep_E | energy of the trailing lepton | |leadlep_eta | pseudorapidity of the leading lepton | |JetInvMass | invariant mass of the jet| |jet_eta| pseudorapidity of the jet | |traillep_eta | pseudorapidity of the trailing lepton | |traillep_phi | azimuthal angle of the trailing lepton | |traillep_d0 | d0 of the track associated to the trailing lepton at the point of closest approach (p.o.a.) | |leadlep_phi | azimuthal angle of the leading lepton | |jet_MV1 | Weight from algorithm based on Multi-Variate technique | |jet_m | reconstructed jet mass | |leadlep_charge | charge of the trailing lepton | |traillep_z0 | z-coordinate of the track associated to the lepton wrt. the primary vertex | |leadlep_pt | transverse momentum of the leading lepton | |leadlep_etcone20 | scalar sum of tracks ET in a cone of R=0.2 around leading lepton, not including lepton ET itself | |lep_n | number of preselected leptons | |n_jets | number of selected jets | |traillep_etcone20 | scalar sum of tracks ET in a cone of R=0.2 around trailing lepton, not including lepton ET itself | |jet_jvf | jet vertex fraction of the jet | |leadlep_d0 | d0 of the track associated to the leading lepton at the point of closest approach (p.o.a.) | |traillep_type | number signifying the lepton type (e, mu, tau) of the trailing lepton | |leadlep_z0 | z-coordinate of the track associated to the leading lepton wrt. the primary vertex | |traillep_ptcone30 | scalar sum of tracks $$p_T$$ in a cone of R=0.3 around the trailing lepton, not including lepton $$p_T$$ itself | |traillep_charge | charge of the trailing lepton |","title":"Variable Names"},{"location":"GitBook/variable_names/#variable-names","text":"If you are using ROOTbrowser to look at the datasets, here are the definitions of the variables. When there are two leptons present in the final state they are ordered by transverse momentum with the \"leading lepton\" having the highest transverse momentum and the \u201ctrailing lepton\" having the next highest value. Take a look at ATLAS events chapter for discussion of primary vertex and Glossary chapter for explanation of ATLAS coordinate system. |branchname | description | |-|-|-| |pvxp_n | number of primary vertices | |leadlep_E | energy of the leading lepton | |traillep_pt | transverse momentum of the trailing lepton | |vxp_z | z-position of the primary vertex (see ATLAS coordinate system)| |leadlep_type | number signifying the leading lepton type (e, mu, tau) of the lepton | |jet_pt | transverse momentum of the jet | |etmiss | Transverse energy of the missing momentum vector | |leadlep_ptcone30 | scalar sum of tracks $$p_T$$ in a cone of R=0.3 around leading lepton, not including lepton $$p_T$$ itself | |traillep_E | energy of the trailing lepton | |leadlep_eta | pseudorapidity of the leading lepton | |JetInvMass | invariant mass of the jet| |jet_eta| pseudorapidity of the jet | |traillep_eta | pseudorapidity of the trailing lepton | |traillep_phi | azimuthal angle of the trailing lepton | |traillep_d0 | d0 of the track associated to the trailing lepton at the point of closest approach (p.o.a.) | |leadlep_phi | azimuthal angle of the leading lepton | |jet_MV1 | Weight from algorithm based on Multi-Variate technique | |jet_m | reconstructed jet mass | |leadlep_charge | charge of the trailing lepton | |traillep_z0 | z-coordinate of the track associated to the lepton wrt. the primary vertex | |leadlep_pt | transverse momentum of the leading lepton | |leadlep_etcone20 | scalar sum of tracks ET in a cone of R=0.2 around leading lepton, not including lepton ET itself | |lep_n | number of preselected leptons | |n_jets | number of selected jets | |traillep_etcone20 | scalar sum of tracks ET in a cone of R=0.2 around trailing lepton, not including lepton ET itself | |jet_jvf | jet vertex fraction of the jet | |leadlep_d0 | d0 of the track associated to the leading lepton at the point of closest approach (p.o.a.) | |traillep_type | number signifying the lepton type (e, mu, tau) of the trailing lepton | |leadlep_z0 | z-coordinate of the track associated to the leading lepton wrt. the primary vertex | |traillep_ptcone30 | scalar sum of tracks $$p_T$$ in a cone of R=0.3 around the trailing lepton, not including lepton $$p_T$$ itself | |traillep_charge | charge of the trailing lepton |","title":"Variable Names"},{"location":"GitBook/EventDisplays/","text":"","title":"Home"},{"location":"GitBook/pictures/","text":"","title":"Home"},{"location":"GitBook/pictures/ROOTbrowser/","text":"","title":"Home"},{"location":"GitBook/pictures/separateSignals/","text":"","title":"Home"},{"location":"Python/python/","text":"ATLAS Open Data Python framework for 13 TeV analyses About This is an analysis code that may be used to analyse the data of the ATLAS published dataset. GitLab repository ATLASDatasetTools13 git clone https://gitlab.cern.ch/meevans/ATLASDatasetTools13.git General Usage Analysis The files in the root directory of the installation are the various run scripts. Configuration files can be found in the Configurations folder. As a first test to check whether everything works fine you can simply run a preconfigured analyis via python RunScript.py -s \"Zmumu\" What you have done here is to run the code in single core mode and specifying that you only want to analyse the Zmumu sample as defined in the Configurations/2lepConfiguration.py. The runscript has several options which may be displayed by typing python RunScript.py --help The options include: -a, --analysis overrides the analysis that is stated in the configuration file -s, --samples comma separated string that contains the keys for a subset of processes to run over -p, --parallel enables running in parallel (default is single core use) -n NWORKERS, --nWorkers NWORKERS specifies the number of workers if multi core usage is desired (default is 4) -c CONFIGFILE, --configfile CONFIGFILE specifies the config file to be read (default is Configurations/Configuration.py) -o OUTPUTDIR, --output OUTPUDIR specifies the output directory you would like to use instead of the one in the configuration file The XConfiguration.py files specify how an analysis should behave. The Job portion of the configuration looks like this: Job = { \"Batch\" : True, (switches progress bar on and off, forced to be off when running in parallel mode) \"Analysis\" : \"ZAnalysis\", (names the analysis to be executed) \"Fraction\" : 0.000001, (determines the fraction of events per file to be analysed) \"MaxEvents\" : 1234567890, (determines the maximum number of events per file to be analysed) \"OutputDirectory\" : \"results/\" (specifies the directory where the output root files should be saved) } The second portion of the configuration file specifies which The locations of the individual files that are to be used for the different processes can be set es such: Processes = { # Diboson processes 2lep > \"WWlvlv\" : \"/eos/project/a/atlas-outreach/projects/open-data/OpenDataTuples/2lep/MC/mc15_13TeV.361600.PwPy8EG_CT10nloME_AZNLOCTEQ6L1_WWlvlv.2lep_raw.root\", (single file) ... \"data_2lep\" : \"/eos/project/a/atlas-outreach/projects/open-data/OpenDataTuples/2lep/Data/data*_2lep.root\", (potentially many files) } The files associated with the processes are found via python's glob module, enabling the use of unix style wildcards. The names chosen for the processes are important as they are the keys that are used later in the infofile.py to determine the necessary scaling factors for correct plotting. Now we want to run over the full set of available samples. For this simply type: python RunScript.py Use the options -p and -n if you have a multi core system and want to use multiple cores. Execution times are between ? to ? hours in single core mode or ~ ? minutes in multi core mode. Plotting Results may be plotted via: python PlotResults.py Configuration/PlotConf_AnalysisName.py In our example case the name of the analysis is ZAnalysis , so type: python PlotResults.py Configuration/PlotConf_ZAnalysis.py The resulting histograms will be put into the Output directory. The plotting configuration file enables the user to steer the plotting process. Each analysis has its own plotting configuration file to accomodate changes in background composition or histograms that the user may want to plot. General information for plotting include the Luminosity and InputDirectory located at the top of the file: config = { \"Luminosity\" : 10064, \"InputDirectory\" : \"results\", ... The names of the histograms to be drawn can be specified like so: \"Histograms\" : { \"etmiss\" : {rebin : 4, log_y : True}, \"lep_n\" : {rebin : 5}, \"lep_pt\" : {}, ... Note that it is possible to supply additional information via a dictionary like structure to further detail the per histogram options. Currently available options are: rebin : int - used to merge X bins into one. Useful in low statistics situations log_y : bool - if True is set as the bool the main depiction will be drawn in logarithmic scale y_margin : float - sets the fraction of whitespace above the largest contribution in the plot. Default value is 0.1. Definition of Paintables and Depictions Each Plot consists of several depictions of paintables . A depiction is a certain standard type of visualising information. Availabe depictions include simple plots, ratios and agreement plots. A paintable is a histogram or stack with added information such as colors and which processes contribute to said histogram. A simple definition of paintables may look like this: 'Paintables': { \"Stack\": { \"Order\" : [\"Diboson\", \"W\", \"Z\", \"single top\", \"ttbar\"], \"Processes\" : { \"Diboson\" : { \"Color\" : \"#fa7921\", \"Contributions\" : [\"WWlvlv\", \"WWlvqq\", \"WZlvll\", \"WZlvvv\", \"WZqqll\", \"WZlvqq\", \"ZZllll\", \"ZZvvll\", \"ZZqqll\"]}, ... }, 'Higgs': { 'Color': '#0000ff', 'Contributions': ['ggH125_WW2lep']}, \"data\" : { \"Contributions\": [\"dataA_2lep\", \"dataB_2lep\", \"dataC_2lep\", \"dataD_2lep\"]} Stack and data are specialised names for paintables . This ensures that only one stack and one data representation are present in the visual results. A Stack shows the different processes specified in \"order\" stacked upon each other to give an idea of the composition of the simulated data. The definitions for these individual processes are defined under \"Processes\". Each process has a certain colour and a list of contributing parts that comprise it. These contributing parts have to fit the keys used in both the run configuration and the infofile.py . data is a specialised paintable which is geared toward the standard representation of data. Since the data does not need to be scaled there is no need to align the used names in contributions with those found in the infofile.py . However, they still have to fit the ones used in the configuration.py . All otherwise named paintables (like \"Higgs\" in the example) are considered as \"overlays\". Overlays are used to show possible signals or to compare shapes between multiple overlays (see for instance in the HWWAnalysis). The paintables can be used in depictions like so: \"Depictions\": { \"Order\" : [\"Main\", \"Data/MC\", \"S/B\"], \"Definitions\" : { \"Data/MC\": { \"type\" : \"Agreement\", \"Paintables\" : [\"data\", \"Stack\"]}, \"Main\": { \"type\" : \"Main\", \"Paintables\": [\"Stack\", \"data\"]}, 'S/B': { 'type' : 'Ratio', 'Paintables' : ['Higgs', 'Stack']}, } There are currently three types of depictions available: Main , Agreement and Ratio . Main type plots will simply show the paintables in a simple plot fashion. Ratio type plots will show the ratio of the first paintable w.r.t. the second paintable. Agreement type plots are typically used to evaluate the agreement between two paintables (usually the stack of predictions and the data). The order of the depictions is determined in line 2 of the code example above. In Depth Information Analysis Code The analysis code is located in the Analysis folder. It will be used to write out histograms for the individual input files which will be used for plotting purposes later. The basic code implementing the protocol to read the files and how the objects can be read is in Tuplereader.py . Have a look there to see which information is available. The general analysis flow can be found in Job.py whereas the base class for all concrete analyses is located in Analysis.py . It is recommended to start out by modifying one of the existing analyses, e.g. the ZAnalysis located in ZAnalysis.py . If you want to add an analysis, make sure that the filename is the same as the class name, otherwise the code will not work.","title":"Python framework"},{"location":"Python/python/#atlas-open-data-python-framework-for-13-tev-analyses","text":"","title":"ATLAS Open Data Python framework for 13 TeV analyses"},{"location":"Python/python/#about","text":"This is an analysis code that may be used to analyse the data of the ATLAS published dataset.","title":"About"},{"location":"Python/python/#gitlab-repository","text":"ATLASDatasetTools13 git clone https://gitlab.cern.ch/meevans/ATLASDatasetTools13.git","title":"GitLab repository"},{"location":"Python/python/#general-usage","text":"","title":"General Usage"},{"location":"Python/python/#analysis","text":"The files in the root directory of the installation are the various run scripts. Configuration files can be found in the Configurations folder. As a first test to check whether everything works fine you can simply run a preconfigured analyis via python RunScript.py -s \"Zmumu\" What you have done here is to run the code in single core mode and specifying that you only want to analyse the Zmumu sample as defined in the Configurations/2lepConfiguration.py. The runscript has several options which may be displayed by typing python RunScript.py --help The options include: -a, --analysis overrides the analysis that is stated in the configuration file -s, --samples comma separated string that contains the keys for a subset of processes to run over -p, --parallel enables running in parallel (default is single core use) -n NWORKERS, --nWorkers NWORKERS specifies the number of workers if multi core usage is desired (default is 4) -c CONFIGFILE, --configfile CONFIGFILE specifies the config file to be read (default is Configurations/Configuration.py) -o OUTPUTDIR, --output OUTPUDIR specifies the output directory you would like to use instead of the one in the configuration file The XConfiguration.py files specify how an analysis should behave. The Job portion of the configuration looks like this: Job = { \"Batch\" : True, (switches progress bar on and off, forced to be off when running in parallel mode) \"Analysis\" : \"ZAnalysis\", (names the analysis to be executed) \"Fraction\" : 0.000001, (determines the fraction of events per file to be analysed) \"MaxEvents\" : 1234567890, (determines the maximum number of events per file to be analysed) \"OutputDirectory\" : \"results/\" (specifies the directory where the output root files should be saved) } The second portion of the configuration file specifies which The locations of the individual files that are to be used for the different processes can be set es such: Processes = { # Diboson processes 2lep > \"WWlvlv\" : \"/eos/project/a/atlas-outreach/projects/open-data/OpenDataTuples/2lep/MC/mc15_13TeV.361600.PwPy8EG_CT10nloME_AZNLOCTEQ6L1_WWlvlv.2lep_raw.root\", (single file) ... \"data_2lep\" : \"/eos/project/a/atlas-outreach/projects/open-data/OpenDataTuples/2lep/Data/data*_2lep.root\", (potentially many files) } The files associated with the processes are found via python's glob module, enabling the use of unix style wildcards. The names chosen for the processes are important as they are the keys that are used later in the infofile.py to determine the necessary scaling factors for correct plotting. Now we want to run over the full set of available samples. For this simply type: python RunScript.py Use the options -p and -n if you have a multi core system and want to use multiple cores. Execution times are between ? to ? hours in single core mode or ~ ? minutes in multi core mode.","title":"Analysis"},{"location":"Python/python/#plotting","text":"Results may be plotted via: python PlotResults.py Configuration/PlotConf_AnalysisName.py In our example case the name of the analysis is ZAnalysis , so type: python PlotResults.py Configuration/PlotConf_ZAnalysis.py The resulting histograms will be put into the Output directory. The plotting configuration file enables the user to steer the plotting process. Each analysis has its own plotting configuration file to accomodate changes in background composition or histograms that the user may want to plot. General information for plotting include the Luminosity and InputDirectory located at the top of the file: config = { \"Luminosity\" : 10064, \"InputDirectory\" : \"results\", ... The names of the histograms to be drawn can be specified like so: \"Histograms\" : { \"etmiss\" : {rebin : 4, log_y : True}, \"lep_n\" : {rebin : 5}, \"lep_pt\" : {}, ... Note that it is possible to supply additional information via a dictionary like structure to further detail the per histogram options. Currently available options are: rebin : int - used to merge X bins into one. Useful in low statistics situations log_y : bool - if True is set as the bool the main depiction will be drawn in logarithmic scale y_margin : float - sets the fraction of whitespace above the largest contribution in the plot. Default value is 0.1.","title":"Plotting"},{"location":"Python/python/#definition-of-paintables-and-depictions","text":"Each Plot consists of several depictions of paintables . A depiction is a certain standard type of visualising information. Availabe depictions include simple plots, ratios and agreement plots. A paintable is a histogram or stack with added information such as colors and which processes contribute to said histogram. A simple definition of paintables may look like this: 'Paintables': { \"Stack\": { \"Order\" : [\"Diboson\", \"W\", \"Z\", \"single top\", \"ttbar\"], \"Processes\" : { \"Diboson\" : { \"Color\" : \"#fa7921\", \"Contributions\" : [\"WWlvlv\", \"WWlvqq\", \"WZlvll\", \"WZlvvv\", \"WZqqll\", \"WZlvqq\", \"ZZllll\", \"ZZvvll\", \"ZZqqll\"]}, ... }, 'Higgs': { 'Color': '#0000ff', 'Contributions': ['ggH125_WW2lep']}, \"data\" : { \"Contributions\": [\"dataA_2lep\", \"dataB_2lep\", \"dataC_2lep\", \"dataD_2lep\"]} Stack and data are specialised names for paintables . This ensures that only one stack and one data representation are present in the visual results. A Stack shows the different processes specified in \"order\" stacked upon each other to give an idea of the composition of the simulated data. The definitions for these individual processes are defined under \"Processes\". Each process has a certain colour and a list of contributing parts that comprise it. These contributing parts have to fit the keys used in both the run configuration and the infofile.py . data is a specialised paintable which is geared toward the standard representation of data. Since the data does not need to be scaled there is no need to align the used names in contributions with those found in the infofile.py . However, they still have to fit the ones used in the configuration.py . All otherwise named paintables (like \"Higgs\" in the example) are considered as \"overlays\". Overlays are used to show possible signals or to compare shapes between multiple overlays (see for instance in the HWWAnalysis). The paintables can be used in depictions like so: \"Depictions\": { \"Order\" : [\"Main\", \"Data/MC\", \"S/B\"], \"Definitions\" : { \"Data/MC\": { \"type\" : \"Agreement\", \"Paintables\" : [\"data\", \"Stack\"]}, \"Main\": { \"type\" : \"Main\", \"Paintables\": [\"Stack\", \"data\"]}, 'S/B': { 'type' : 'Ratio', 'Paintables' : ['Higgs', 'Stack']}, } There are currently three types of depictions available: Main , Agreement and Ratio . Main type plots will simply show the paintables in a simple plot fashion. Ratio type plots will show the ratio of the first paintable w.r.t. the second paintable. Agreement type plots are typically used to evaluate the agreement between two paintables (usually the stack of predictions and the data). The order of the depictions is determined in line 2 of the code example above.","title":"Definition of Paintables and Depictions"},{"location":"Python/python/#in-depth-information","text":"","title":"In Depth Information"},{"location":"Python/python/#analysis-code","text":"The analysis code is located in the Analysis folder. It will be used to write out histograms for the individual input files which will be used for plotting purposes later. The basic code implementing the protocol to read the files and how the objects can be read is in Tuplereader.py . Have a look there to see which information is available. The general analysis flow can be found in Job.py whereas the base class for all concrete analyses is located in Analysis.py . It is recommended to start out by modifying one of the existing analyses, e.g. the ZAnalysis located in ZAnalysis.py . If you want to add an analysis, make sure that the filename is the same as the class name, otherwise the code will not work.","title":"Analysis Code"},{"location":"vm/","text":"About This is an analysis code that may be used to analyse the data of the ATLAS published dataset. Why do you need a virtual machine? Virtualization allows you to create an operating system in the operating system and test programs without installing them on the host machine. Also virtualization allows you to do penetration testing. There are a generous amount of Virtual Machines (VM): ORACLE VirtualBox , Windows Visual , VMware Workstation , Colinux , AlphaVM-Pro , DOSBox , Linux-VServer , PearPC , VirtualLogix VLX etc. (read more about VM on wikipedia ). Among these VM, Oracle VirtualBox is one of the best. VirtualBox is a virtualization software product for Microsoft Windows, Linux, FreeBSD, Mac OS X, Solaris / OpenSolaris, ReactOS, DOS and others. Collaboration Software Products - Top To Look For: \u2014 USB support - VirtualBox implements a virtual USB controller and supports connecting devices to a virtual machine via USB. \u2014 Built-in RDP server, as well as support for USB client devices over RDP \u2014 the user can connect to the virtual machine remotely using an RDP-compatible client. \u2014 iSCSI initiator - VirtualBox contains an integral iSCSI initiator that makes it possible to use an iSCSI worker as a virtual disk without the need to support the iSCSI guest system. \u2014 Support for various types of network interaction (NAT, Host Networking via Bridged, Internal). \u2014 Support for Shared Folders, allowing you to share files between the host and guest systems. \u2014 and finally VirtualBox is a free to use. Also with VirtualBox, you can use Windows, Linux, Mac OS X, Solaris to run their bundles on one computer. Each virtual machine is called a guest, and your main computer (the OS installed on it) is called a host. The point is that you can run several guest systems in the host\u2019s operating system (direct inside it). VM with ROOT and Jupyter VirtualBox installation Follow the instructions below to install the VM on your computer: - What version to download ? Assumption of what your operating system. In this review we will explain how to install VirtualBox on Windows 10. Installing VirtualBox on all versions of Windows is identical. First download the installation file. \u2014 Download VirtualBox you can free on the official website . \u2014 So, after you have downloaded the latest version of Virtual Box, let's proceed to the installation. Find the downloaded file in your computer (usually the downloaded file is in \u0421:\\Users\\User\\Downloads\\\"filename\" ), run the program and click \"Next\". \u2014 After that, the component selection window will appear. Without changing anything, click \"Next\". \u2014 In the next window, without any changing click \"Next\" \u2014 Now a window will appear that says that the Internet will be temporarily disabled during the installation of the program. Click \"Yes\". \u2014 And click \"Install\" to begin the installation. \u2014 After the installation process is complete, click \"Finish\" \u2014 Now you will see a clean window of your virtual machine without any operating systems: Configure VirtualBox \u2014 If you have English installed on your system, the program will automatically change the interface language to English when you first start it. If this does not happen, go to the menu \u201cFile\u201d -> \u201cSettings\\or/Preferences\u201d and on the Languages tab select your language . In principle, in the settings of VirtualBox there is nothing more to change. How to install an operating system in your virtual machine? First, download the ready operating system (.ova file with ROOT and Jupiter inside) from this link ! If you want to install your operating system from scratch, then see how to do it in this section . \u2014 After you have downloaded the ready file, start the VirtualBox. Go to the menu \"File\" -> \u201cImport Appliance...\u201d (or perform the same function with the combination of buttons: \"Ctrl\" + \"I\" ). \u2014 In the window that appears, select the downloaded \".ova\" file from the Downloads folder and click \"Next\": \u2014 After click \"Import\" without any changes: \u2014 The operating system is importing: \u2014 Now your Virtual Machine with Linux operating system is ready to work, start it by clicking and use: Jupiter terminal start and Notebooks run errors in VM After starting your VM and running Notebooks, you may encounter the following error (look at the red frames in the photo below): To solve this error , follow these simple steps: \u2014 \u0421lose notebooks and terminal \u2014 Run terminal again and type this code ./run-server-jupyter.sh to start Jupiter \u2014 You have restarted your terminal and server successfully \u2014 Open notebook in your browser and restart kernel by clicking restart button Now your terminal and server should work. Notebook also runs without errors.","title":"Virtual Machines"},{"location":"vm/#about","text":"This is an analysis code that may be used to analyse the data of the ATLAS published dataset. Why do you need a virtual machine? Virtualization allows you to create an operating system in the operating system and test programs without installing them on the host machine. Also virtualization allows you to do penetration testing. There are a generous amount of Virtual Machines (VM): ORACLE VirtualBox , Windows Visual , VMware Workstation , Colinux , AlphaVM-Pro , DOSBox , Linux-VServer , PearPC , VirtualLogix VLX etc. (read more about VM on wikipedia ). Among these VM, Oracle VirtualBox is one of the best. VirtualBox is a virtualization software product for Microsoft Windows, Linux, FreeBSD, Mac OS X, Solaris / OpenSolaris, ReactOS, DOS and others. Collaboration Software Products - Top To Look For: \u2014 USB support - VirtualBox implements a virtual USB controller and supports connecting devices to a virtual machine via USB. \u2014 Built-in RDP server, as well as support for USB client devices over RDP \u2014 the user can connect to the virtual machine remotely using an RDP-compatible client. \u2014 iSCSI initiator - VirtualBox contains an integral iSCSI initiator that makes it possible to use an iSCSI worker as a virtual disk without the need to support the iSCSI guest system. \u2014 Support for various types of network interaction (NAT, Host Networking via Bridged, Internal). \u2014 Support for Shared Folders, allowing you to share files between the host and guest systems. \u2014 and finally VirtualBox is a free to use. Also with VirtualBox, you can use Windows, Linux, Mac OS X, Solaris to run their bundles on one computer. Each virtual machine is called a guest, and your main computer (the OS installed on it) is called a host. The point is that you can run several guest systems in the host\u2019s operating system (direct inside it).","title":"About"},{"location":"vm/#vm-with-root-and-jupyter","text":"VirtualBox installation Follow the instructions below to install the VM on your computer: - What version to download ? Assumption of what your operating system. In this review we will explain how to install VirtualBox on Windows 10. Installing VirtualBox on all versions of Windows is identical. First download the installation file. \u2014 Download VirtualBox you can free on the official website . \u2014 So, after you have downloaded the latest version of Virtual Box, let's proceed to the installation. Find the downloaded file in your computer (usually the downloaded file is in \u0421:\\Users\\User\\Downloads\\\"filename\" ), run the program and click \"Next\". \u2014 After that, the component selection window will appear. Without changing anything, click \"Next\". \u2014 In the next window, without any changing click \"Next\" \u2014 Now a window will appear that says that the Internet will be temporarily disabled during the installation of the program. Click \"Yes\". \u2014 And click \"Install\" to begin the installation. \u2014 After the installation process is complete, click \"Finish\" \u2014 Now you will see a clean window of your virtual machine without any operating systems: Configure VirtualBox \u2014 If you have English installed on your system, the program will automatically change the interface language to English when you first start it. If this does not happen, go to the menu \u201cFile\u201d -> \u201cSettings\\or/Preferences\u201d and on the Languages tab select your language . In principle, in the settings of VirtualBox there is nothing more to change. How to install an operating system in your virtual machine? First, download the ready operating system (.ova file with ROOT and Jupiter inside) from this link ! If you want to install your operating system from scratch, then see how to do it in this section . \u2014 After you have downloaded the ready file, start the VirtualBox. Go to the menu \"File\" -> \u201cImport Appliance...\u201d (or perform the same function with the combination of buttons: \"Ctrl\" + \"I\" ). \u2014 In the window that appears, select the downloaded \".ova\" file from the Downloads folder and click \"Next\": \u2014 After click \"Import\" without any changes: \u2014 The operating system is importing: \u2014 Now your Virtual Machine with Linux operating system is ready to work, start it by clicking and use: Jupiter terminal start and Notebooks run errors in VM After starting your VM and running Notebooks, you may encounter the following error (look at the red frames in the photo below): To solve this error , follow these simple steps: \u2014 \u0421lose notebooks and terminal \u2014 Run terminal again and type this code ./run-server-jupyter.sh to start Jupiter \u2014 You have restarted your terminal and server successfully \u2014 Open notebook in your browser and restart kernel by clicking restart button Now your terminal and server should work. Notebook also runs without errors.","title":"VM with ROOT and Jupyter"},{"location":"vm/appendix/","text":"Ubuntu Create a virtual machine \u2014 Click the \"New\" button. \u2014 In the settings window specify the \"Name\" (in the future you can change), the \"Type\" and \"Version\" of the operating system and click \"Next\". For example - Name: My_Ubuntu (o_0), Type: Linux, Version: Ubuntu (64-bit). \u2014 The machine claims that the minimum memory size (RAM) requirements for full-fledged work Linux,, 1024MB. But if you want your machine to work well, then select the volume for more depending on the RAM of your computer (2 GB if RAM of your computer 8 GB) and click \"Next\". Sometimes even more, it all depends on the tasks and how many Virtual Machines you will run at the same time. \u2014 So we went to create a virtual hard disk. Click \"Create\": \u2014 Specify the type of hard disk (VDI - VirtualBox Disk Image) and click \"Next\": (Choose the first item, as it is easier. You have created a file that will simulate the hard disk of your virtual machine. If necessary, you can transfer it to another computer and run there). \u2014 In the window that appears, put a tick in \"Dynamically allocated\", after click \"Next\": -The hard disk size set at least 80 GB (or more) and click \"Create\". \u2014 Now the Virtual Machine is ready, but without an operating system. Start the Virtual Machine by clicking on the right mouse button and select \"Start\" -> \"Normal start\" . \u2014 When you first start you will be prompted to select the installation file from which the installation will be performed. You can download the installation file from the official website . Select the installation file from the Downloads folder (or where you saved it) and click \"Start\". \u2014 In the window that appears, select the operating system language and click on \"Install Ubuntu\". Next, select the keyboard language. \u2014 After selecting the keyboard language, just click on \"Continue\" \u2014 Disk layout . You can choose installation type. Simply format the entire hard drive and install Ubuntu on it, or select the manual option (Set the checkbox to \"Something else\" option and click \"Continue\"): \u2014 In the opened window, if you have not yet marked up the hard drive, you need to create a partition table, to do this, click \"New Partition Table...\". \u2014 Four sections are recommended for Linux: / - ext4, size 10-50 GB, for system installation /boot - ext2, size 100 MB, for bootloader files swap - swap, size equals RAM, for swap /home - ext4, all remaining space \u2014 To create a new section, click the \"+\" button: \u2014 Here you need to specify the mount point, for example, / or /home , size, file system and you can set a label: \u2014 In the end, you should have something like this: Then click \"Install Now\". \u2014 You should have this window: Check that everything is correct, click \"Continue\". \u2014 Select your time zone: \u2014 Enter your Username, computer name and password: \u2014 Installing your operating system: \u2014 Enjoy your virtual machine: VM with Docker container and Jupyter Lab","title":"Appendix"},{"location":"vm/appendix/#ubuntu","text":"Create a virtual machine \u2014 Click the \"New\" button. \u2014 In the settings window specify the \"Name\" (in the future you can change), the \"Type\" and \"Version\" of the operating system and click \"Next\". For example - Name: My_Ubuntu (o_0), Type: Linux, Version: Ubuntu (64-bit). \u2014 The machine claims that the minimum memory size (RAM) requirements for full-fledged work Linux,, 1024MB. But if you want your machine to work well, then select the volume for more depending on the RAM of your computer (2 GB if RAM of your computer 8 GB) and click \"Next\". Sometimes even more, it all depends on the tasks and how many Virtual Machines you will run at the same time. \u2014 So we went to create a virtual hard disk. Click \"Create\": \u2014 Specify the type of hard disk (VDI - VirtualBox Disk Image) and click \"Next\": (Choose the first item, as it is easier. You have created a file that will simulate the hard disk of your virtual machine. If necessary, you can transfer it to another computer and run there). \u2014 In the window that appears, put a tick in \"Dynamically allocated\", after click \"Next\": -The hard disk size set at least 80 GB (or more) and click \"Create\". \u2014 Now the Virtual Machine is ready, but without an operating system. Start the Virtual Machine by clicking on the right mouse button and select \"Start\" -> \"Normal start\" . \u2014 When you first start you will be prompted to select the installation file from which the installation will be performed. You can download the installation file from the official website . Select the installation file from the Downloads folder (or where you saved it) and click \"Start\". \u2014 In the window that appears, select the operating system language and click on \"Install Ubuntu\". Next, select the keyboard language. \u2014 After selecting the keyboard language, just click on \"Continue\" \u2014 Disk layout . You can choose installation type. Simply format the entire hard drive and install Ubuntu on it, or select the manual option (Set the checkbox to \"Something else\" option and click \"Continue\"): \u2014 In the opened window, if you have not yet marked up the hard drive, you need to create a partition table, to do this, click \"New Partition Table...\". \u2014 Four sections are recommended for Linux: / - ext4, size 10-50 GB, for system installation /boot - ext2, size 100 MB, for bootloader files swap - swap, size equals RAM, for swap /home - ext4, all remaining space \u2014 To create a new section, click the \"+\" button: \u2014 Here you need to specify the mount point, for example, / or /home , size, file system and you can set a label: \u2014 In the end, you should have something like this: Then click \"Install Now\". \u2014 You should have this window: Check that everything is correct, click \"Continue\". \u2014 Select your time zone: \u2014 Enter your Username, computer name and password: \u2014 Installing your operating system: \u2014 Enjoy your virtual machine:","title":"Ubuntu"},{"location":"vm/appendix/#vm-with-docker-container-and-jupyter-lab","text":"","title":"VM with Docker container and Jupyter Lab"}]}